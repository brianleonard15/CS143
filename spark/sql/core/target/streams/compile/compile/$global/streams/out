[0m[[0mdebug[0m] [0m[0m
[0m[[0mdebug[0m] [0mInitial source changes: [0m
[0m[[0mdebug[0m] [0m	removed:Set()[0m
[0m[[0mdebug[0m] [0m	added: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/package-info.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF22.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MetadataBuilder.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF1.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF20.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF9.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF18.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF13.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF19.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/Row.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/DiskHashedRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF12.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF6.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/ExamplePointUDT.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JsonRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetFilters.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF17.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF21.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF15.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkSqlSerializer.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF5.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/CS143Utils.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/QueryExecutionException.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF10.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/LogicalRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnStats.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF11.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLConf.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetConverter.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF16.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF8.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnType.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF4.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashedRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/Metadata.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF3.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF2.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF7.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF14.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/filters.scala)[0m
[0m[[0mdebug[0m] [0m	modified: Set()[0m
[0m[[0mdebug[0m] [0mRemoved products: Set()[0m
[0m[[0mdebug[0m] [0mExternal API changes: API Changes: Set()[0m
[0m[[0mdebug[0m] [0mModified binary dependencies: Set()[0m
[0m[[0mdebug[0m] [0mInitial directly invalidated sources: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/package-info.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF22.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MetadataBuilder.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF1.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF20.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF9.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF18.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF13.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF19.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/Row.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/DiskHashedRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF12.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF6.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/ExamplePointUDT.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JsonRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetFilters.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF17.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF21.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF15.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkSqlSerializer.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF5.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/CS143Utils.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/QueryExecutionException.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF10.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/LogicalRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnStats.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF11.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLConf.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetConverter.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF16.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF8.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnType.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF4.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashedRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/Metadata.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF3.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF2.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF7.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF14.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/filters.scala)[0m
[0m[[0mdebug[0m] [0m[0m
[0m[[0mdebug[0m] [0mSources indirectly invalidated by:[0m
[0m[[0mdebug[0m] [0m	product: Set()[0m
[0m[[0mdebug[0m] [0m	binary dep: Set()[0m
[0m[[0mdebug[0m] [0m	external source: Set()[0m
[0m[[0mdebug[0m] [0mAll initially invalidated sources: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/package-info.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF22.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MetadataBuilder.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF1.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF20.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF9.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF18.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF13.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF19.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/Row.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/DiskHashedRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF12.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF6.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/ExamplePointUDT.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JsonRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetFilters.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF17.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF21.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF15.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkSqlSerializer.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF5.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/CS143Utils.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/QueryExecutionException.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF10.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/LogicalRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnStats.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF11.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLConf.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetConverter.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF16.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF8.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnType.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF4.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashedRelation.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/Metadata.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF3.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF2.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF7.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF14.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/filters.scala)[0m
[0m[[0mdebug[0m] [0mRecompiling all 115 sources: invalidated sources (115) exceeded 50.0% of all sources[0m
[0m[[0minfo[0m] [0mCompiling 71 Scala sources and 44 Java sources to /Users/bleonard/Documents/Databases/spark/sql/core/target/scala-2.10/classes...[0m
[0m[[0mdebug[0m] [0mGetting compiler-interface from component compiler for Scala 2.10.4[0m
[0m[[0mdebug[0m] [0mGetting compiler-interface from component compiler for Scala 2.10.4[0m
[0m[[0mdebug[0m] [0mRunning cached compiler 6b1de8f7, interfacing (CompilerInterface) with Scala compiler version 2.10.4[0m
[0m[[0mdebug[0m] [0mCalling Scala compiler with arguments  (CompilerInterface):[0m
[0m[[0mdebug[0m] [0m	-unchecked[0m
[0m[[0mdebug[0m] [0m	-deprecation[0m
[0m[[0mdebug[0m] [0m	-feature[0m
[0m[[0mdebug[0m] [0m	-P:genjavadoc:out=/Users/bleonard/Documents/Databases/spark/sql/core/target/java[0m
[0m[[0mdebug[0m] [0m	-Xplugin:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/genjavadoc-plugin_2.10.4-0.8.jar[0m
[0m[[0mdebug[0m] [0m	-bootclasspath[0m
[0m[[0mdebug[0m] [0m	/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre/classes:/Users/bleonard/.sbt/boot/scala-2.10.4/lib/scala-library.jar[0m
[0m[[0mdebug[0m] [0m	-classpath[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/target/scala-2.10/classes:/Users/bleonard/Documents/Databases/spark/core/target/scala-2.10/classes:/Users/bleonard/Documents/Databases/spark/network/common/target/scala-2.10/classes:/Users/bleonard/Documents/Databases/spark/network/shuffle/target/scala-2.10/classes:/Users/bleonard/Documents/Databases/spark/sql/catalyst/target/scala-2.10/classes:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/netty-all-4.0.23.Final.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/unused-1.0.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/chill_2.10-0.5.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/chill-java-0.5.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/kryo-2.21.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/reflectasm-1.07-shaded.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/minlog-1.2.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/objenesis-1.2.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/hadoop-client-1.0.4.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/hadoop-core-1.0.4.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/xmlenc-0.52.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-math-2.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-configuration-1.6.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-collections-3.2.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-lang-2.4.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-logging-1.1.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-digester-1.8.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-beanutils-1.7.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-beanutils-core-1.8.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-net-2.2.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-el-1.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/hsqldb-1.8.0.10.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/oro-2.0.8.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jets3t-0.7.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-httpclient-3.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/curator-recipes-2.4.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/curator-framework-2.4.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/curator-client-2.4.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/zookeeper-3.4.5.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/slf4j-log4j12-1.7.5.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/log4j-1.2.17.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jline-0.9.94.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/guava-14.0.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-plus-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/orbits/javax.transaction-1.1.1.v201105210645.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-webapp-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-xml-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-util-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-servlet-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-security-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-server-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/orbits/javax.servlet-3.0.0.v201112011016.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-continuation-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-http-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-io-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jetty-jndi-8.1.14.v20131031.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/orbits/javax.mail.glassfish-1.4.1.v201005082020.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/orbits/javax.activation-1.1.0.v201105071233.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-lang3-3.3.2.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-math3-3.1.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jsr305-1.3.9.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/slf4j-api-1.7.5.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jul-to-slf4j-1.7.5.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jcl-over-slf4j-1.7.5.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/compress-lzf-1.0.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/snappy-java-1.1.1.6.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/lz4-1.2.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/RoaringBitmap-0.4.5.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/akka-remote_2.10-2.3.4-spark.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/akka-actor_2.10-2.3.4-spark.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/config-1.2.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/netty-3.8.0.Final.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/protobuf-java-2.5.0-spark.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/uncommons-maths-1.2.2a.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/akka-slf4j_2.10-2.3.4-spark.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/json4s-jackson_2.10-3.2.10.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/json4s-core_2.10-3.2.10.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/json4s-ast_2.10-3.2.10.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/paranamer-2.6.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/scalap-2.10.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/jackson-databind-2.3.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/jackson-annotations-2.3.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/jackson-core-2.3.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/mesos-0.18.1-shaded-protobuf.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/stream-2.7.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/metrics-core-3.0.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/metrics-jvm-3.0.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/metrics-json-3.0.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/bundles/metrics-graphite-3.0.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/tachyon-client-0.5.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/tachyon-0.5.0.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-io-2.4.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/pyrolite-2.0.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/py4j-0.8.2.1.jar:/Users/bleonard/.sbt/boot/scala-2.10.4/lib/scala-compiler.jar:/Users/bleonard/.sbt/boot/scala-2.10.4/lib/scala-reflect.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/quasiquotes_2.10-2.0.1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/parquet-column-1.6.0rc3.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/parquet-common-1.6.0rc3.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/parquet-encoding-1.6.0rc3.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/parquet-generator-1.6.0rc3.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/commons-codec-1.5.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/parquet-hadoop-1.6.0rc3.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/parquet-format-2.2.0-rc1.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/parquet-jackson-1.6.0rc3.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jackson-mapper-asl-1.9.11.jar:/Users/bleonard/Documents/Databases/spark/lib_managed/jars/jackson-core-asl-1.9.11.jar[0m
[0m[[33mwarn[0m] [0m/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/CS143Utils.scala:48: non-variable type argument org.apache.spark.sql.catalyst.expressions.Row in type pattern java.util.ArrayList[org.apache.spark.sql.catalyst.expressions.Row] is unchecked since it is eliminated by erasure[0m
[0m[[33mwarn[0m] [0m        case value: JavaArrayList[Row] => value[0m
[0m[[33mwarn[0m] [0m                    ^[0m
[0m[[33mwarn[0m] [0m/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/CS143Utils.scala:50: comparing values of types Unit and Null using `!=' will always yield true[0m
[0m[[33mwarn[0m] [0m      }) != null) {[0m
[0m[[33mwarn[0m] [0m         ^[0m
[0m[[33mwarn[0m] [0m/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala:368: method fromCaseClassString in object DataType is deprecated: Use DataType.fromJson instead[0m
[0m[[33mwarn[0m] [0m    Try(DataType.fromJson(string)).getOrElse(DataType.fromCaseClassString(string)) match {[0m
[0m[[33mwarn[0m] [0m                                                      ^[0m
[0m[[33mwarn[0m] [0mthree warnings found[0m
[0m[[0mdebug[0m] [0mScala compilation took 9.872645 s[0m
[0m[[0mdebug[0m] [0mForking javac: /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/bin/javac @/var/folders/md/gpkdz3hs0m19687gx_4_t4wm0000gn/T/sbt_69cfcc91/argfile[0m
[0m[[0mdebug[0m] [0mjavac returned exit code: 0[0m
[0m[[0mdebug[0m] [0mJava compilation took 0.851434 s[0m
[0m[[0mdebug[0m] [0mJava analysis took 0.118291 s[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MetadataBuilder.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MetadataBuilder.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MetadataBuilder.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MetadataBuilder.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MetadataBuilder.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, equals, putLong, putBoolean, putString, build, putMetadata, putDouble, getMap, notifyAll, putMetadataArray, putStringArray, <init>, putLongArray, putBooleanArray, toString, MetadataBuilder, getClass, withMetadata, hashCode, putDoubleArray.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MetadataBuilder.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(build, <init>, MetadataBuilder, withMetadata)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, $asInstanceOf, equals, asInstanceOf, synchronized, $isInstanceOf, notifyAll, UDFRegistration, isInstanceOf, registerFunction, ==, clone, $init$, registerPython, toString, !=, getClass, ne, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(asInstanceOf, UDFRegistration, isInstanceOf, ==, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala: Set(asInstanceOf, isInstanceOf, ==, toString, getClass, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala: Set(isInstanceOf)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala: Set(asInstanceOf, isInstanceOf, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala: Set(asInstanceOf, isInstanceOf, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala: Set(asInstanceOf, isInstanceOf, ==, toString, !=, getClass, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala: Set(asInstanceOf, isInstanceOf, ==, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(asInstanceOf, UDFRegistration, ==, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala: Set(asInstanceOf, isInstanceOf, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala: Set(asInstanceOf, isInstanceOf, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala: Set(UDFRegistration, registerFunction)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(asInstanceOf, isInstanceOf, ==, toString, !=, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(asInstanceOf, isInstanceOf, ==, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mNone of the modified names appears in /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala. This dependency is not being considered for invalidation.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(asInstanceOf, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(asInstanceOf, UDFRegistration, registerFunction)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(asInstanceOf, isInstanceOf, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala: Set(asInstanceOf, isInstanceOf, ==, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala: Set(!=)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala: Set(asInstanceOf, isInstanceOf, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mNone of the modified names appears in /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala. This dependency is not being considered for invalidation.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala: Set(asInstanceOf, isInstanceOf, ==, toString, !=, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala: Set(asInstanceOf, isInstanceOf, ==, toString, !=, getClass, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(asInstanceOf, isInstanceOf, ==, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala: Set(asInstanceOf, isInstanceOf, ==, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala: Set(asInstanceOf, isInstanceOf, ==, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala: Set(==, toString)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF18.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF18.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF18.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF18.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF18.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF18.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF18.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF18)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnType.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnType.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnType.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnType.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnType.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, SHORT, BINARY, wait, $asInstanceOf, ByteArrayColumnType, setField, actualSize, equals, asInstanceOf, synchronized, copyField, $isInstanceOf, typeId, scalaTag, notifyAll, isInstanceOf, FLOAT, getField, <init>, DATE, STRING, apply, ==, clone, DOUBLE, INT, defaultSize, BYTE, toString, !=, ColumnType, NativeColumnType, getClass, TIMESTAMP, dataType, GENERIC, BOOLEAN, ne, LONG, eq, ##, finalize, extract, hashCode, append.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(asInstanceOf, typeId, isInstanceOf, <init>, apply, ==, defaultSize, toString, ColumnType, dataType, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnStats.scala: Set(SHORT, BINARY, actualSize, asInstanceOf, FLOAT, <init>, DATE, STRING, apply, ==, DOUBLE, INT, defaultSize, BYTE, TIMESTAMP, dataType, GENERIC, BOOLEAN, ne, LONG)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala: Set(typeId, <init>, apply, ColumnType, NativeColumnType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(SHORT, BINARY, actualSize, asInstanceOf, typeId, FLOAT, <init>, DATE, STRING, ==, DOUBLE, INT, defaultSize, BYTE, ColumnType, NativeColumnType, TIMESTAMP, GENERIC, BOOLEAN, LONG, append)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala: Set(SHORT, BINARY, asInstanceOf, typeId, FLOAT, <init>, DATE, STRING, ==, DOUBLE, INT, BYTE, ColumnType, NativeColumnType, TIMESTAMP, GENERIC, BOOLEAN, LONG, extract)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala: Set(SHORT, setField, actualSize, asInstanceOf, copyField, typeId, scalaTag, getField, <init>, STRING, apply, ==, clone, INT, defaultSize, BYTE, toString, !=, ColumnType, NativeColumnType, dataType, BOOLEAN, LONG, extract, append)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m	asParser, keyword, accept, parser2packrat.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following member ref dependencies of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	clearCache, notify, wait, lookupCachedData, copy$default$2, cacheQuery, $asInstanceOf, cacheQuery$default$2, cacheLock, CachedData, productArity, equals, readLock, uncacheQuery, asInstanceOf, synchronized, $isInstanceOf, canEqual, cacheQuery$default$3, productPrefix, notifyAll, CacheManager, isInstanceOf, <init>, uncacheTable, cacheTable, ==, clone, tryUncacheQuery, cachedRepresentation, isCached, $init$, tryUncacheQuery$default$2, copy, cachedData, useCachedData, toString, !=, invalidateCache, getClass, copy$default$1, ne, writeLock, eq, productIterator, uncacheQuery$default$2, plan, ##, finalize, productElement, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(cacheQuery, asInstanceOf, isInstanceOf, <init>, tryUncacheQuery, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala: Set(asInstanceOf, isInstanceOf, <init>, cacheTable, ==, toString, ne, eq, plan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(asInstanceOf, CacheManager, isInstanceOf, <init>, ==, tryUncacheQuery, useCachedData, toString, ne, plan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString, getClass, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala: Set(isInstanceOf)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala: Set(lookupCachedData, cacheQuery, cacheLock, CachedData, readLock, uncacheQuery, asInstanceOf, CacheManager, isInstanceOf, <init>, ==, cachedRepresentation, cachedData, toString, writeLock, eq, plan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala: Set(productArity, asInstanceOf, isInstanceOf, <init>, ==, toString, eq, plan, productElement)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString, !=, getClass, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, copy, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(asInstanceOf, <init>, ==, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, copy, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mNone of the modified names appears in /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala. This dependency is not being considered for invalidation.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString, !=, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala: Set(<init>)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(asInstanceOf, <init>, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(asInstanceOf)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(cacheQuery, asInstanceOf, isInstanceOf, <init>, tryUncacheQuery, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala: Set(<init>, !=)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala: Set(<init>)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, copy, toString, !=, ne, eq, plan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString, !=, getClass, ne, eq, plan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString, ne, plan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala: Set(asInstanceOf, isInstanceOf, <init>, cacheTable, ==, toString, ne, eq, plan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala: Set(<init>, ==, toString)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/LogicalRelation.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/LogicalRelation.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/LogicalRelation.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/LogicalRelation.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/LogicalRelation.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, LogicalRelation, resolveNesting, wait, $asInstanceOf, numberedTreeString, relation, attributeMap, printSchema, map, productArity, equals, statistics, treeString, transformChildrenDown, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, childrenResolved, log_, synchronized, nodeName, $isInstanceOf, logTrace, asCode, canEqual, expressions, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, resolveChildren, cleanArgs, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, references, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, resolved, ==, fastEquals, transformExpressionsUp, clone, sameResult, foreach, resolve, newInstance, copy, inputSet, toString, logError, !=, collect, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, statePrefix, eq, productIterator, log, ##, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala: Set(LogicalRelation, relation, attributeMap, map, asInstanceOf, expressions, isInstanceOf, references, <init>, apply, flatMap, ==, collect, output, transform)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(LogicalRelation, map, asInstanceOf, expressions, <init>, schema, apply, ==, newInstance, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(LogicalRelation, map, schemaString, asInstanceOf, expressions, isInstanceOf, references, <init>, schema, apply, flatMap, ==, foreach, toString, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JsonRDD.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JsonRDD.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JsonRDD.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JsonRDD.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JsonRDD.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	toDecimal, notify, wait, $asInstanceOf, toTimestamp, equals, createSchema, parseJson, asInstanceOf, asRow, log_, synchronized, $isInstanceOf, compatibleType, JsonRDD, logTrace, isTraceEnabled, inferSchema, inferSchema$default$2, logName, notifyAll, toLong, nullTypeToStringType, isInstanceOf, ==, clone, allKeysWithValueTypes, enforceCorrectType, toDouble, toJsonObjectString, toString, toDate, logError, typeOfArray, !=, getClass, logWarning, initializeIfNecessary, ne, rowToJSON, eq, log, ##, finalize, scalafy, hashCode, typeOfPrimitiveValue, logDebug, toJsonArrayString, logInfo, jsonStringToRow, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala: Set(asInstanceOf, JsonRDD, inferSchema, isInstanceOf, ==, toDouble, toString, eq, jsonStringToRow)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(asInstanceOf, JsonRDD, isInstanceOf, toString, ne, rowToJSON)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(asInstanceOf, JsonRDD, inferSchema, nullTypeToStringType, ==, ne, jsonStringToRow)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(asInstanceOf, JsonRDD, inferSchema, nullTypeToStringType, isInstanceOf, ==, toString, ne, jsonStringToRow)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, printSchema, buildSideKeyGenerator, map, hashJoin, BroadcastLeftSemiJoinHash, productArity, equals, treeString, transformChildrenDown, buildSide, schemaString, argString, streamedPlan, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, left, codegenEnabled, nodeName, $isInstanceOf, buildPlan, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, leftKeys, rightKeys, references, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, buildKeys, sparkContext, outputPartitioning, copy$default$3, copy, inputSet, streamSideKeyGenerator, toString, logError, !=, collect, getClass, streamedKeys, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, right, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, hashJoin, buildSide, asInstanceOf, left, codegenEnabled, expressions, isInstanceOf, leftKeys, rightKeys, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF4.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF4.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF4.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF4.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF4.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF4.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF4)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF4.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF19.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF19.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF19.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF19.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF19.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF19.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF19)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF19.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF1.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF1.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF1.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF1.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF1.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF1.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF1)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF1.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, execute, wait, requiredChildDistribution, $asInstanceOf, numberedTreeString, printSchema, map, equals, treeString, transformChildrenDown, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, BinaryNode, log_, synchronized, UnaryNode, left, codegenEnabled, SparkPlan, nodeName, $isInstanceOf, logTrace, asCode, expressions, outputSet, isTraceEnabled, makeCopy, transformUp, logName, notifyAll, readResolve, otherCopyArgs, missingInput, isInstanceOf, stringArgs, child, references, currentContext, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, sparkContext, outputPartitioning, $init$, LeafNode, inputSet, toString, logError, !=, collect, getClass, logWarning, output, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, newProjection, statePrefix, eq, log, right, ##, newOrdering, finalize, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(execute, map, schemaString, asInstanceOf, codegenEnabled, SparkPlan, expressions, isInstanceOf, references, currentContext, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala: Set(simpleString, treeString, schemaString, isInstanceOf, schema, sqlContext, output)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(map, asInstanceOf, expressions, <init>, schema, apply, ==, sqlContext, sparkContext, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala: Set(map, asInstanceOf, left, SparkPlan, expressions, isInstanceOf, references, <init>, apply, flatMap, ==, collect, output, transform, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(map, asInstanceOf, expressions, isInstanceOf, <init>, schema, apply, executeCollect, sqlContext, sparkContext, toString, collect, output, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(execute, map, schemaString, asInstanceOf, codegenEnabled, SparkPlan, expressions, isInstanceOf, references, currentContext, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(map, asInstanceOf, expressions, isInstanceOf, references, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, !=, output, ne, transform, eq, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(map, asInstanceOf, expressions, isInstanceOf, <init>, schema, apply, executeCollect, sqlContext, sparkContext, toString, collect, output, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala: Set(expressions, log)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(execute, map, schemaString, asInstanceOf, codegenEnabled, SparkPlan, expressions, isInstanceOf, references, currentContext, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala: Set(map, asInstanceOf, left, SparkPlan, expressions, isInstanceOf, references, <init>, apply, flatMap, ==, collect, output, transform, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(execute, map, schemaString, asInstanceOf, codegenEnabled, SparkPlan, expressions, isInstanceOf, references, currentContext, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala: Set(map, asInstanceOf, isInstanceOf, <init>, apply, ==, foreach, toString, collect, logWarning, output, transformDown, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala: Set(map, asInstanceOf, SparkPlan, expressions, isInstanceOf, <init>, schema, apply, ==, sqlContext, LeafNode, toString, output, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala: Set(execute, map, asInstanceOf, BinaryNode, left, SparkPlan, expressions, isInstanceOf, <init>, apply, flatMap, ==, foreach, sparkContext, outputPartitioning, toString, collect, output, ne, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala: Set(execute, map, asInstanceOf, UnaryNode, SparkPlan, expressions, isInstanceOf, child, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, LeafNode, toString, !=, getClass, output, ne, eq, log, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala: Set(execute, map, asInstanceOf, UnaryNode, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, toString, collect, output, ne, transform, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala: Set(execute, asInstanceOf, BinaryNode, left, SparkPlan, expressions, isInstanceOf, <init>, apply, ==, toString, output, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala: Set(children, execute, map, asInstanceOf, transformExpressions, UnaryNode, SparkPlan, expressions, outputSet, isInstanceOf, child, references, <init>, apply, flatMap, ==, fastEquals, newMutableProjection, toString, !=, collect, getClass, output, ne, transform, withNewChildren, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala: Set(children, execute, map, asInstanceOf, BinaryNode, UnaryNode, left, SparkPlan, expressions, isInstanceOf, child, <init>, schema, apply, executeCollect, ==, sqlContext, newMutableProjection, newPredicate, foreach, sparkContext, toString, output, eq, right, newOrdering)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala: Set(children, execute, map, asInstanceOf, UnaryNode, SparkPlan, expressions, isInstanceOf, child, <init>, apply, ==, toString, output, newProjection, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala: Set(map, asInstanceOf, left, SparkPlan, expressions, isInstanceOf, references, <init>, apply, flatMap, ==, collect, output, transform, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(execute, map, asInstanceOf, left, SparkPlan, expressions, isInstanceOf, child, <init>, schema, apply, flatMap, ==, sqlContext, newPredicate, foreach, sparkContext, LeafNode, toString, output, ne, eq, right, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala: Set(execute, map, asInstanceOf, UnaryNode, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, toString, output, newProjection, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(map, asInstanceOf, expressions, isInstanceOf, <init>, schema, apply, executeCollect, sqlContext, sparkContext, toString, collect, output, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/package.scala: Set(SparkPlan, expressions, <init>)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(execute, map, schemaString, asInstanceOf, codegenEnabled, SparkPlan, expressions, isInstanceOf, references, currentContext, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala: Set(execute, map, asInstanceOf, BinaryNode, left, SparkPlan, expressions, isInstanceOf, <init>, apply, flatMap, ==, newPredicate, outputPartitioning, toString, collect, output, ne, newProjection, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala: Set(execute, map, asInstanceOf, BinaryNode, left, SparkPlan, expressions, isInstanceOf, <init>, apply, ==, sqlContext, sparkContext, outputPartitioning, toString, collect, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala: Set(children, execute, requiredChildDistribution, map, asInstanceOf, UnaryNode, SparkPlan, expressions, transformUp, isInstanceOf, child, <init>, apply, ==, sqlContext, newMutableProjection, sparkContext, outputPartitioning, toString, !=, output, ne, withNewChildren, eq, logDebug)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala: Set(simpleString, execute, map, asInstanceOf, UnaryNode, SparkPlan, isInstanceOf, child, <init>, schema, apply, ==, foreach, sparkContext, toString, !=, getClass, output, ne, transform, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala: Set(execute, map, asInstanceOf, BinaryNode, left, SparkPlan, expressions, isInstanceOf, <init>, apply, ==, toString, output, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala: Set(execute, asInstanceOf, BinaryNode, left, SparkPlan, expressions, isInstanceOf, <init>, apply, ==, outputPartitioning, toString, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala: Set(execute, map, asInstanceOf, BinaryNode, left, SparkPlan, expressions, isInstanceOf, <init>, apply, ==, sparkContext, outputPartitioning, toString, collect, output, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala: Set(simpleString, map, asInstanceOf, SparkPlan, expressions, isInstanceOf, child, <init>, apply, ==, sqlContext, foreach, sparkContext, toString, logWarning, output, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala: Set(execute, map, asInstanceOf, UnaryNode, SparkPlan, expressions, isInstanceOf, child, <init>, schema, apply, flatMap, ==, newMutableProjection, inputSet, toString, !=, collect, output, ne, transform, newProjection, eq, log)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala: Set(execute, map, asInstanceOf, BinaryNode, left, SparkPlan, expressions, isInstanceOf, <init>, apply, ==, sparkContext, toString, collect, output, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala: Set(left, SparkPlan, expressions, <init>, apply, ==, newMutableProjection, !=, output, ne, newProjection, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(execute, map, schemaString, asInstanceOf, codegenEnabled, SparkPlan, expressions, isInstanceOf, references, currentContext, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala: Set(map, asInstanceOf, isInstanceOf, <init>, apply, ==, sqlContext, toString, getClass, ne, eq, logDebug)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, SparkPlan, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnStats.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnStats.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnStats.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnStats.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnStats.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, count, wait, $asInstanceOf, ShortColumnStats, lowerBound, forAttribute, equals, asInstanceOf, NoopColumnStats, synchronized, $isInstanceOf, StringColumnStats, lower, collectedStatistics, upper, notifyAll, isInstanceOf, BooleanColumnStats, upperBound, BinaryColumnStats, <init>, schema, ==, clone, ColumnStatisticsSchema, GenericColumnStats, x$4, TimestampColumnStats, sizeInBytes, $init$, FloatColumnStats, toString, ByteColumnStats, gatherStats, !=, getClass, DateColumnStats, IntColumnStats, nullCount, ColumnStats, ne, eq, PartitionStatistics, ##, finalize, hashCode, LongColumnStats, DoubleColumnStats.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala: Set(gatherStats, nullCount)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(count, lowerBound, forAttribute, asInstanceOf, collectedStatistics, isInstanceOf, upperBound, <init>, schema, ==, sizeInBytes, toString, nullCount, ne, eq, PartitionStatistics)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(ShortColumnStats, asInstanceOf, StringColumnStats, BooleanColumnStats, BinaryColumnStats, <init>, ==, GenericColumnStats, TimestampColumnStats, FloatColumnStats, ByteColumnStats, DateColumnStats, IntColumnStats, ColumnStats, LongColumnStats, DoubleColumnStats)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF14.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF14.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF14.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF14.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF14.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF14.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF14)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF14.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, $asInstanceOf, equals, asInstanceOf, synchronized, $isInstanceOf, notifyAll, UDFRegistration, isInstanceOf, registerFunction, ==, clone, $init$, toString, !=, getClass, ne, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(asInstanceOf, UDFRegistration, registerFunction)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(asInstanceOf, UDFRegistration, ==, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF16.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF16.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF16.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF16.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF16.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	UDF16, call.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(UDF16, call)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF16.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m	SetAccumulatorParam, DebugQuery.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, saveAsParquetFile, SchemaRDDLike, $asInstanceOf, insertInto, printSchema, equals, schemaString, asInstanceOf, synchronized, $isInstanceOf, notifyAll, baseLogicalPlan, isInstanceOf, registerAsTable, super$toString, baseSchemaRDD, ==, sqlContext, clone, $init$, toString, !=, getClass, saveAsTable, queryExecution, ne, registerTempTable, eq, logicalPlan, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala: Set(SchemaRDDLike, insertInto, schemaString, baseLogicalPlan, isInstanceOf, super$toString, baseSchemaRDD, sqlContext, queryExecution, registerTempTable, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala: Set(asInstanceOf, isInstanceOf, ==, toString, queryExecution, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(SchemaRDDLike, asInstanceOf, baseLogicalPlan, baseSchemaRDD, sqlContext, toString, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(schemaString, asInstanceOf, isInstanceOf, ==, sqlContext, toString, queryExecution, ne, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala: Set(asInstanceOf, isInstanceOf, ==, toString, !=, getClass, queryExecution, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala: Set(saveAsParquetFile, asInstanceOf, isInstanceOf, ==, sqlContext, ne, registerTempTable)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala: Set(asInstanceOf, isInstanceOf, ==, sqlContext, toString, queryExecution, ne, registerTempTable, eq, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(SchemaRDDLike, asInstanceOf, baseLogicalPlan, isInstanceOf, sqlContext, toString, queryExecution, ne, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(asInstanceOf, baseSchemaRDD, ==, sqlContext, ne, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala: Set(asInstanceOf, isInstanceOf, ==, sqlContext, toString, getClass, ne, registerTempTable, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala: Set(asInstanceOf, isInstanceOf, ==, toString, queryExecution, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(SchemaRDDLike, asInstanceOf, baseLogicalPlan, baseSchemaRDD, sqlContext, toString, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(SchemaRDDLike, asInstanceOf, baseLogicalPlan, isInstanceOf, sqlContext, toString, queryExecution, ne, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(schemaString, asInstanceOf, isInstanceOf, ==, sqlContext, toString, queryExecution, ne, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala: Set(asInstanceOf, isInstanceOf, ==, toString, !=, getClass, queryExecution, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala: Set(saveAsParquetFile, asInstanceOf, isInstanceOf, ==, sqlContext, ne, registerTempTable)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala: Set(asInstanceOf, isInstanceOf, ==, sqlContext, toString, queryExecution, ne, registerTempTable, eq, logicalPlan)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/package.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/package.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/package.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/package.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/package.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, package, wait, $asInstanceOf, equals, asInstanceOf, synchronized, $isInstanceOf, notifyAll, isInstanceOf, ==, clone, toString, !=, getClass, ne, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, super$extractTo, decoder, wait, $asInstanceOf, nullsBuffer, BooleanColumnAccessor, LongColumnAccessor, DoubleColumnAccessor, equals, asInstanceOf, pos, synchronized, FloatColumnAccessor, $isInstanceOf, nextNullIndex, ShortColumnAccessor, TimestampColumnAccessor, buffer, ColumnAccessor, NativeColumnAccessor, columnType, StringColumnAccessor, BinaryColumnAccessor, ByteColumnAccessor, notifyAll, initialize, isInstanceOf, GenericColumnAccessor, <init>, apply, super$hasNext, ==, DateColumnAccessor, clone, seenNulls, $init$, BasicColumnAccessor, toString, !=, super$underlyingBuffer, getClass, extractTo, nullCount, extractSingle, ne, hasNext, IntColumnAccessor, eq, super$initialize, underlyingBuffer, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala: Set(decoder, buffer, ColumnAccessor, NativeColumnAccessor, columnType, apply, super$hasNext, super$underlyingBuffer, hasNext, super$initialize)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala: Set(super$extractTo, nullsBuffer, pos, nextNullIndex, ColumnAccessor, super$hasNext, ==, seenNulls, nullCount, super$initialize, underlyingBuffer)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(asInstanceOf, ColumnAccessor, columnType, isInstanceOf, <init>, apply, ==, toString, extractTo, nullCount, ne, hasNext, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala: Set(BooleanColumnAccessor, LongColumnAccessor, DoubleColumnAccessor, asInstanceOf, FloatColumnAccessor, ShortColumnAccessor, TimestampColumnAccessor, buffer, ColumnAccessor, NativeColumnAccessor, columnType, StringColumnAccessor, BinaryColumnAccessor, ByteColumnAccessor, initialize, GenericColumnAccessor, <init>, ==, DateColumnAccessor, BasicColumnAccessor, extractSingle, IntColumnAccessor)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala: Set(BooleanColumnAccessor, LongColumnAccessor, DoubleColumnAccessor, asInstanceOf, FloatColumnAccessor, ShortColumnAccessor, TimestampColumnAccessor, buffer, ColumnAccessor, NativeColumnAccessor, columnType, StringColumnAccessor, BinaryColumnAccessor, ByteColumnAccessor, initialize, GenericColumnAccessor, <init>, ==, DateColumnAccessor, BasicColumnAccessor, extractSingle, IntColumnAccessor)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, printSchema, buildSideKeyGenerator, map, hashJoin, productArity, equals, treeString, transformChildrenDown, buildSide, schemaString, argString, streamedPlan, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, left, codegenEnabled, nodeName, $isInstanceOf, buildPlan, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, leftKeys, rightKeys, references, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, executeCollect, ==, LeftSemiJoinHash, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, buildKeys, sparkContext, outputPartitioning, copy$default$3, copy, inputSet, streamSideKeyGenerator, toString, logError, !=, collect, getClass, streamedKeys, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, right, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, hashJoin, buildSide, asInstanceOf, left, codegenEnabled, expressions, isInstanceOf, leftKeys, rightKeys, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/QueryExecutionException.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/QueryExecutionException.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/QueryExecutionException.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/QueryExecutionException.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/QueryExecutionException.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, printStackTrace, getLocalizedMessage, wait, $asInstanceOf, equals, fillInStackTrace, initCause, asInstanceOf, synchronized, $isInstanceOf, getCause, notifyAll, isInstanceOf, getStackTrace, getStackTraceElement, <init>, getMessage, setStackTrace, getSuppressed, ==, getStackTraceDepth, clone, addSuppressed, toString, !=, getClass, ne, eq, QueryExecutionException, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, RDDConversions, resolveNesting, execute, wait, LogicalRDD, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, productToRowRdd, PhysicalRDD, printSchema, map, productArity, equals, statistics, treeString, transformChildrenDown, schemaString, ExistingRdd, argString, asInstanceOf, transformExpressions, generateTreeString, childrenResolved, log_, synchronized, codegenEnabled, nodeName, $isInstanceOf, logTrace, asCode, canEqual, expressions, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, resolveChildren, cleanArgs, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, rdd, references, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, resolved, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, sameResult, foreach, resolve, sparkContext, outputPartitioning, newInstance, SparkLogicalPlan, copy, inputSet, toString, logError, !=, collect, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, alreadyPlanned, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala: Set(simpleString, LogicalRDD, treeString, schemaString, isInstanceOf, schema, sqlContext, output)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(LogicalRDD, map, asInstanceOf, expressions, rdd, <init>, schema, apply, ==, sqlContext, sparkContext, newInstance, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala: Set(map, asInstanceOf, expressions, isInstanceOf, rdd, references, <init>, apply, flatMap, ==, collect, output, transform)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(LogicalRDD, map, asInstanceOf, expressions, isInstanceOf, rdd, <init>, schema, apply, executeCollect, sqlContext, sparkContext, newInstance, toString, collect, output, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(RDDConversions, execute, productToRowRdd, map, schemaString, asInstanceOf, codegenEnabled, expressions, isInstanceOf, rdd, references, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(RDDConversions, productToRowRdd, map, statistics, asInstanceOf, codegenEnabled, expressions, isInstanceOf, rdd, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, alreadyPlanned, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF10.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF10.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF10.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF10.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF10.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF10.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF10)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF10.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, decoder, wait, $asInstanceOf, equals, asInstanceOf, synchronized, $isInstanceOf, CompressibleColumnAccessor, notifyAll, initialize, isInstanceOf, super$hasNext, ==, clone, $init$, toString, !=, super$underlyingBuffer, getClass, extractTo, extractSingle, ne, hasNext, eq, super$initialize, underlyingBuffer, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala: Set(decoder, CompressibleColumnAccessor, super$hasNext, super$underlyingBuffer, hasNext, super$initialize)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala: Set(super$hasNext, ==, super$initialize, underlyingBuffer)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(asInstanceOf, isInstanceOf, ==, toString, extractTo, ne, hasNext, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala: Set(asInstanceOf, CompressibleColumnAccessor, initialize, ==, extractSingle)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala: Set(asInstanceOf, CompressibleColumnAccessor, initialize, ==, extractSingle)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	ParquetTypeInfo, isPrimitiveType, notify, originalType, wait, primitiveType, copy$default$2, $asInstanceOf, fromDataType$default$4, BYTES_FOR_PRECISION, productArity, equals, writeMetaData, fromDataType, asInstanceOf, log_, synchronized, $isInstanceOf, fromDataType$default$3, decimalMetadata, convertToAttributes, toDataType, logTrace, canEqual, copy$default$4, isTraceEnabled, productPrefix, convertFromString, logName, notifyAll, readSchemaFromFile, isInstanceOf, <init>, ParquetTypesConverter, ==, fromPrimitiveDataType, convertFromAttributes, clone, convertToString, copy$default$3, copy, toString, length, logError, !=, getClass, logWarning, copy$default$1, initializeIfNecessary, readMetaData, toPrimitiveDataType, ne, eq, productIterator, log, ##, finalize, productElement, hashCode, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala: Set(asInstanceOf, isInstanceOf, <init>, ParquetTypesConverter, ==, convertFromAttributes, convertToString, toString, !=, getClass, ne, eq, log, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(asInstanceOf, readSchemaFromFile, isInstanceOf, <init>, ParquetTypesConverter, ==, convertToString, toString, !=, ne, eq, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala: Set(writeMetaData, asInstanceOf, readSchemaFromFile, isInstanceOf, <init>, ParquetTypesConverter, ==, toString, readMetaData)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala: Set(BYTES_FOR_PRECISION, asInstanceOf, convertToAttributes, convertFromString, isInstanceOf, <init>, ParquetTypesConverter, ==, convertFromAttributes, convertToString, toString, !=, ne, log)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetConverter.scala: Set(isPrimitiveType, asInstanceOf, isInstanceOf, <init>, ParquetTypesConverter, ==, copy, toString, length, !=, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF15.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF15.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF15.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF15.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF15.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF15.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF15.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF15)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, execute, wait, requiredChildDistribution, projections, copy$default$2, $asInstanceOf, numberedTreeString, printSchema, map, productArity, equals, treeString, transformChildrenDown, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, codegenEnabled, nodeName, $isInstanceOf, logTrace, asCode, canEqual, expressions, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, child, references, <init>, mapChildren, schema, transformExpressionsDown, Expand, apply, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, sparkContext, outputPartitioning, copy$default$3, copy, inputSet, toString, logError, !=, collect, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(projections, map, asInstanceOf, codegenEnabled, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLConf.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLConf.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLConf.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLConf.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLConf.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLConf.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, IN_MEMORY_PARTITION_PRUNING, getConf, inMemoryPartitionPruning, parquetCompressionCodec, COLUMN_NAME_OF_CORRUPT_RECORD, wait, externalSortEnabled, $asInstanceOf, numShufflePartitions, equals, PARQUET_FILTER_PUSHDOWN_ENABLED, broadcastTimeout, EXTERNAL_SORT, clear, SQLConf, asInstanceOf, synchronized, unsetConf, codegenEnabled, $isInstanceOf, PARQUET_COMPRESSION, autoBroadcastJoinThreshold, defaultSizeInBytes, columnBatchSize, isParquetBinaryAsString, notifyAll, COLUMN_BATCH_SIZE, PARQUET_BINARY_AS_STRING, isInstanceOf, SHUFFLE_PARTITIONS, parquetFilterPushDown, DEFAULT_SIZE_IN_BYTES, AUTO_BROADCASTJOIN_THRESHOLD, ==, clone, THRIFTSERVER_POOL, useCompression, $init$, DIALECT, Deprecated, toString, columnNameOfCorruptRecord, !=, setConf, getClass, COMPRESS_CACHED, MAPRED_REDUCE_TASKS, dialect, ne, CODEGEN_ENABLED, PARQUET_CACHE_METADATA, eq, settings, BROADCAST_TIMEOUT, getAllConfs, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala: Set(clear, asInstanceOf, columnBatchSize, isInstanceOf, ==, useCompression, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala: Set(asInstanceOf, defaultSizeInBytes, isInstanceOf, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala: Set(getConf, SQLConf, asInstanceOf, isInstanceOf, ==, toString, !=, getClass, ne, PARQUET_CACHE_METADATA, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(asInstanceOf, ==, columnNameOfCorruptRecord, dialect, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(getConf, SQLConf, asInstanceOf, isParquetBinaryAsString, isInstanceOf, parquetFilterPushDown, ==, toString, !=, setConf, ne, PARQUET_CACHE_METADATA, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(inMemoryPartitionPruning, asInstanceOf, defaultSizeInBytes, isInstanceOf, ==, useCompression, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala: Set(SQLConf, defaultSizeInBytes)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala: Set(parquetCompressionCodec, asInstanceOf, defaultSizeInBytes, isParquetBinaryAsString, isInstanceOf, ==, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala: Set(codegenEnabled, !=)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala: Set(asInstanceOf, isInstanceOf, ==, toString, columnNameOfCorruptRecord, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(getConf, numShufflePartitions, SQLConf, asInstanceOf, codegenEnabled, isInstanceOf, ==, toString, columnNameOfCorruptRecord, setConf, dialect, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala: Set(getConf, SQLConf, SHUFFLE_PARTITIONS)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala: Set(broadcastTimeout, asInstanceOf, isInstanceOf, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala: Set(numShufflePartitions, asInstanceOf, isInstanceOf, ==, toString, !=, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(externalSortEnabled, asInstanceOf, codegenEnabled, autoBroadcastJoinThreshold, isInstanceOf, parquetFilterPushDown, ==, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala: Set(getConf, asInstanceOf, unsetConf, isInstanceOf, ==, setConf, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala: Set(getConf, numShufflePartitions, SQLConf, asInstanceOf, isInstanceOf, SHUFFLE_PARTITIONS, ==, Deprecated, toString, setConf, MAPRED_REDUCE_TASKS, ne, eq, getAllConfs)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala: Set(asInstanceOf, isInstanceOf, ==, toString, getClass, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala: Set(isInstanceOf)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala: Set(clear, asInstanceOf, columnBatchSize, isInstanceOf, ==, useCompression, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala: Set(asInstanceOf, defaultSizeInBytes, isInstanceOf, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala: Set(getConf, SQLConf, asInstanceOf, isInstanceOf, ==, toString, !=, getClass, ne, PARQUET_CACHE_METADATA, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala: Set(asInstanceOf, isInstanceOf, ==, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(asInstanceOf, ==, columnNameOfCorruptRecord, dialect, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala: Set(asInstanceOf, isInstanceOf, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala: Set(asInstanceOf, isInstanceOf, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mNone of the modified names appears in /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala. This dependency is not being considered for invalidation.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(getConf, SQLConf, asInstanceOf, isParquetBinaryAsString, isInstanceOf, parquetFilterPushDown, ==, toString, !=, setConf, ne, PARQUET_CACHE_METADATA, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(inMemoryPartitionPruning, asInstanceOf, defaultSizeInBytes, isInstanceOf, ==, useCompression, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala: Set(SQLConf, defaultSizeInBytes)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(asInstanceOf, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(asInstanceOf)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(asInstanceOf, isInstanceOf, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala: Set(parquetCompressionCodec, asInstanceOf, defaultSizeInBytes, isParquetBinaryAsString, isInstanceOf, ==, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala: Set(codegenEnabled, !=)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala: Set(asInstanceOf, isInstanceOf, ==, toString, columnNameOfCorruptRecord, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala: Set(getConf, SQLConf, SHUFFLE_PARTITIONS)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala: Set(numShufflePartitions, asInstanceOf, isInstanceOf, ==, toString, !=, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala: Set(clear, asInstanceOf, isInstanceOf, ==, toString, !=, getClass, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(externalSortEnabled, asInstanceOf, codegenEnabled, autoBroadcastJoinThreshold, isInstanceOf, parquetFilterPushDown, ==, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala: Set(getConf, asInstanceOf, unsetConf, isInstanceOf, ==, setConf, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala: Set(getConf, numShufflePartitions, SQLConf, asInstanceOf, isInstanceOf, SHUFFLE_PARTITIONS, ==, Deprecated, toString, setConf, MAPRED_REDUCE_TASKS, ne, eq, getAllConfs)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala: Set(==, toString)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, unapply, simpleString, children, predicates, resolveNesting, execute, wait, stats, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, computeSizeInBytes, relation, copy$default$5, batchSize, printSchema, apply$default$8, map, productArity, equals, statistics, treeString, transformChildrenDown, schemaString, argString, asInstanceOf, transformExpressions, InMemoryColumnarTableScan, apply$default$7, generateTreeString, childrenResolved, log_, synchronized, codegenEnabled, nodeName, <init>$default$7, $isInstanceOf, inMemoryPartitionPruningEnabled, partitionStatistics, partitionFilters, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, resolveChildren, cleanArgs, logName, notifyAll, attributes, readResolve, cachedColumnBuffers, otherCopyArgs, missingInput, isInstanceOf, stringArgs, child, <init>$default$8, references, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, resolved, tableName, executeCollect, ==, _cachedColumnBuffers, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, sameResult, foreach, useCompression, resolve, sparkContext, outputPartitioning, CachedBatch, buffers, newInstance, copy$default$3, readBatches, copy, inputSet, statisticsToBePropagated, _statistics, batchStats, toString, logError, !=, recache, InMemoryRelation, collect, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, copy$default$6, ne, transform, buildBuffers, statsFor, withNewChildren, newProjection, statePrefix, eq, productIterator, withOutput, storageLevel, log, readPartitions, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, buildFilter, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala: Set(map, asInstanceOf, cachedColumnBuffers, isInstanceOf, <init>, apply, tableName, ==, sameResult, foreach, useCompression, toString, recache, InMemoryRelation, collect, logWarning, output, transformDown, eq, withOutput, storageLevel)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(unapply, predicates, relation, map, statistics, asInstanceOf, InMemoryColumnarTableScan, codegenEnabled, expressions, isInstanceOf, child, <init>, apply, flatMap, tableName, ==, sqlContext, sparkContext, toString, InMemoryRelation, collect, output, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/CartesianProduct.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, printSchema, map, productArity, equals, treeString, transformChildrenDown, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, left, codegenEnabled, nodeName, $isInstanceOf, logTrace, asCode, canEqual, expressions, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, references, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, executeCollect, ==, CartesianProduct, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, sparkContext, outputPartitioning, copy, inputSet, toString, logError, !=, collect, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, right, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, expressions, isInstanceOf, <init>, apply, flatMap, ==, CartesianProduct, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF22.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF22.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF22.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF22.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF22.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	UDF22, call.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(UDF22, call)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF22.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF3.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF3.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF3.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF3.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF3.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF3.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF3)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF3.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m	DslAttribute, DslString, DslSymbol, DslExpression, byteToLiteral, longToLiteral, shortToLiteral, baseRelationToSchemaRDD, intToLiteral, binaryToLiteral, doubleToLiteral, StringToAttributeConversionHelper, booleanToLiteral, dateToLiteral, createSchemaRDD, timestampToLiteral, symbolToUnresolvedAttribute, decimalToLiteral, bigDecimalToLiteral, stringToLiteral, logicalPlanToSparkQuery, floatToLiteral.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following member ref dependencies of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF6.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF6.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF6.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF6.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF6.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	UDF6, call.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(UDF6, call)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF6.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, pruneFilterProjectRaw, children, wait, $asInstanceOf, equals, asInstanceOf, pruneFilterProject, log_, synchronized, $isInstanceOf, logTrace, isTraceEnabled, logName, notifyAll, isInstanceOf, DataSourceStrategy, selectFilters, apply, ==, clone, toString, logError, !=, getClass, logWarning, initializeIfNecessary, ne, eq, log, ##, finalize, hashCode, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(asInstanceOf, isInstanceOf, DataSourceStrategy, apply, ==, toString, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala source file has the following implicit definitions changed:[0m
[0m[[0mdebug[0m] [0m	DslAttribute, DslString, DslSymbol, DslExpression, byteToLiteral, longToLiteral, shortToLiteral, baseRelationToSchemaRDD, intToLiteral, binaryToLiteral, doubleToLiteral, StringToAttributeConversionHelper, booleanToLiteral, dateToLiteral, createSchemaRDD, timestampToLiteral, symbolToUnresolvedAttribute, decimalToLiteral, bigDecimalToLiteral, stringToLiteral, logicalPlanToSparkQuery, floatToLiteral.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following member ref dependencies of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala[0m
[0m[[0mdebug[0m] [0mThe following member ref dependencies of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala are invalidated:[0m
[0m[[0mdebug[0m] [0m	/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, UncacheTableCommand, simpleString, children, DescribeCommand, sideEffectResult, resolveNesting, execute, wait, ExplainCommand, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, extended, printSchema, map, productArity, equals, statistics, treeString, transformChildrenDown, schemaString, argString, kv, asInstanceOf, transformExpressions, run, generateTreeString, childrenResolved, RunnableCommand, log_, synchronized, codegenEnabled, nodeName, $isInstanceOf, logTrace, asCode, canEqual, expressions, outputSet, isTraceEnabled, CacheTableCommand, makeCopy, transformUp, productPrefix, resolveChildren, cleanArgs, logName, notifyAll, cmd, otherCopyArgs, missingInput, isInstanceOf, stringArgs, child, references, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, resolved, tableName, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, sameResult, foreach, resolve, sparkContext, outputPartitioning, copy$default$3, copy, inputSet, toString, ExecutedCommand, logError, !=, collect, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, SetCommand, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, isLazy, log, logicalPlan, plan, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(extended, map, statistics, kv, asInstanceOf, codegenEnabled, expressions, isInstanceOf, child, <init>, apply, flatMap, tableName, ==, sqlContext, sparkContext, toString, collect, output, ne, isLazy, logicalPlan, plan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala: Set(map, kv, asInstanceOf, RunnableCommand, isInstanceOf, <init>, apply, tableName, ==, sqlContext, toString, getClass, ne, eq, logDebug)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(execute, map, schemaString, asInstanceOf, codegenEnabled, expressions, isInstanceOf, references, <init>, schema, apply, flatMap, tableName, ==, sqlContext, foreach, sparkContext, toString, ne, logicalPlan, plan)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF8.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF8.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF8.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF8.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF8.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF8.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF8)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF8.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, $asInstanceOf, equals, withSQLConf, asInstanceOf, synchronized, withTempPath, $isInstanceOf, ParquetTest, withTempTable, withParquetTable, notifyAll, isInstanceOf, withTempDir, ==, withParquetRDD, sqlContext, clone, $init$, configuration, toString, !=, getClass, ne, withParquetFile, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, HashAggregation, wait, HashJoin, $asInstanceOf, productArity, equals, BroadcastNestedLoopJoin, canBeCodeGened, canEvaluate, asInstanceOf, log_, synchronized, splitDisjunctivePredicates, makeBroadcastHashJoin, $isInstanceOf, logTrace, canEqual, isTraceEnabled, splitConjunctivePredicates, productPrefix, logName, notifyAll, readResolve, isInstanceOf, TakeOrdered, SparkStrategies, <init>, apply, ==, CartesianProduct, LeftSemiJoin, clone, CommandStrategy, planLater, toString, singleRowRdd, strategies, logError, !=, getClass, logWarning, ParquetOperations, BasicOperators, initializeIfNecessary, allAggregates, ne, InMemoryScans, numPartitions, eq, productIterator, log, ##, finalize, productElement, hashCode, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString, getClass, ne, eq, logDebug)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala: Set(isInstanceOf)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString, logWarning, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala: Set(productArity, asInstanceOf, isInstanceOf, <init>, apply, ==, toString, eq, productElement)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString, !=, getClass, ne, eq, log, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(asInstanceOf, <init>, apply, ==, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala: Set(asInstanceOf, isInstanceOf, TakeOrdered, <init>, apply, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Expand.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala: Set(log)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString, !=, ne, eq, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString, ne, eq, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala: Set(<init>)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(asInstanceOf, <init>, apply, toString, numPartitions)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(asInstanceOf)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, toString, ne, numPartitions)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkPlan.scala: Set(<init>, apply, !=, log)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/TestSQLContext.scala: Set(<init>)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString, !=, ne, numPartitions, eq, logDebug)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString, !=, getClass, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(HashAggregation, HashJoin, BroadcastNestedLoopJoin, canBeCodeGened, asInstanceOf, makeBroadcastHashJoin, isInstanceOf, TakeOrdered, SparkStrategies, <init>, apply, ==, CartesianProduct, LeftSemiJoin, CommandStrategy, planLater, toString, singleRowRdd, ParquetOperations, BasicOperators, allAggregates, ne, InMemoryScans, numPartitions)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala: Set(asInstanceOf, isInstanceOf, <init>, apply, ==, toString, logWarning, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(HashAggregation, HashJoin, BroadcastNestedLoopJoin, asInstanceOf, isInstanceOf, TakeOrdered, SparkStrategies, <init>, apply, ==, CartesianProduct, LeftSemiJoin, CommandStrategy, toString, ParquetOperations, BasicOperators, ne, InMemoryScans)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala: Set(<init>, apply, ==, toString)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, $asInstanceOf, equals, asInstanceOf, columnStats, pos, synchronized, $isInstanceOf, build, nulls, super$appendFrom, initialize$default$3, notifyAll, initialize, isInstanceOf, super$build, ==, clone, $init$, appendFrom, toString, NullableColumnBuilder, initialize$default$2, !=, getClass, buildNonNulls, nullCount, ne, eq, super$initialize, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(nulls, super$appendFrom, ==, buildNonNulls, nullCount, super$initialize)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala: Set(columnStats, pos, nulls, super$appendFrom, super$build, NullableColumnBuilder, nullCount, super$initialize)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(asInstanceOf, columnStats, build, isInstanceOf, ==, appendFrom, toString, nullCount, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(nulls, super$appendFrom, ==, buildNonNulls, nullCount, super$initialize)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(asInstanceOf, columnStats, pos, initialize, ==, NullableColumnBuilder)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(asInstanceOf, columnStats, pos, initialize, ==, NullableColumnBuilder)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, fraction, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, partial, seed, printSchema, CacheProject, map, productArity, ExternalSort, equals, treeString, transformChildrenDown, schemaString, argString, asInstanceOf, Distinct, transformExpressions, generateTreeString, log_, Intersect, Limit, synchronized, left, conditionEvaluator, withReplacement, codegenEnabled, nodeName, $isInstanceOf, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, PartitionProject, logName, notifyAll, OutputFaker, otherCopyArgs, missingInput, isInstanceOf, TakeOrdered, stringArgs, child, Sample, references, global, <init>, mapChildren, condition, schema, transformExpressionsDown, apply, flatMap, executeCollect, ==, Project, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, sortOrder, sparkContext, outputPartitioning, buildProjection, Except, copy$default$3, copy, inputSet, generateIterator, toString, logError, !=, collect, getClass, sortBasedShuffleOn, logWarning, Union, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, projectList, Filter, Sort, ne, limit, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, ord, right, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(fraction, seed, map, asInstanceOf, left, withReplacement, codegenEnabled, expressions, isInstanceOf, TakeOrdered, child, global, <init>, condition, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, projectList, ne, limit, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala: Set(map, asInstanceOf, left, expressions, isInstanceOf, references, <init>, apply, flatMap, ==, collect, output, projectList, Filter, transform, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(execute, map, schemaString, asInstanceOf, codegenEnabled, expressions, isInstanceOf, TakeOrdered, references, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, projectList, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, precision, isFixed, equals, getPrecision, scale, LongType, IntegerType, TimestampType, notifyAll, DoubleType, getScale, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, DecimalType, BooleanType, ByteType, hasPrecisionInfo, FloatType, isUnlimited, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, precision, isFixed, getPrecision, scale, LongType, IntegerType, TimestampType, DoubleType, getScale, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, DecimalType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetConverter.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetConverter.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetConverter.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetConverter.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetConverter.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	addInt, elements, checkGrowBuffer, notify, updateBinary, parent, hasDictionarySupport, updateInt, addLong, CatalystPrimitiveRowConverter, isPrimitive, NativeType, wait, $asInstanceOf, size, FieldType, updateDecimal, map, equals, keyValueConverter, MAP_SCHEMA_NAME, keyConverter, updateFloat, getCurrentRecord, addBoolean, asInstanceOf, CatalystStructConverter, synchronized, readDecimal, updateDouble, $isInstanceOf, CatalystMapConverter, MapScalaType, updateShort, updateBoolean, buffer, CatalystArrayContainsNullConverter, ArrayScalaType, setDictionary, CatalystNativeArrayConverter, notifyAll, CatalystPrimitiveConverter, asPrimitiveConverter, isRootConverter, isInstanceOf, CatalystGroupConverter, <init>, updateField, schema, CatalystConverter, MAP_KEY_SCHEMA_NAME, addValueFromDictionary, MAP_VALUE_SCHEMA_NAME, ==, updateString, createRootConverter, clone, createConverter, addDouble, asGroupConverter, ARRAY_ELEMENTS_SCHEMA_NAME, end, toString, !=, converters, CatalystArrayConverter, valueConverter, getClass, ARRAY_CONTAINS_NULL_BAG_SCHEMA_NAME, converter, start, current, ne, addBinary, elementType, clearBuffer, updateByte, eq, updateLong, getConverter, ##, finalize, StructScalaType, index, hashCode, addFloat, INITIAL_ARRAY_SIZE, capacity.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala: Set(<init>, schema, CatalystConverter, ==, ARRAY_ELEMENTS_SCHEMA_NAME, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala: Set(addLong, size, map, MAP_SCHEMA_NAME, getCurrentRecord, addBoolean, asInstanceOf, MapScalaType, ArrayScalaType, isInstanceOf, <init>, schema, CatalystConverter, MAP_KEY_SCHEMA_NAME, MAP_VALUE_SCHEMA_NAME, ==, createRootConverter, addDouble, ARRAY_ELEMENTS_SCHEMA_NAME, toString, !=, ARRAY_CONTAINS_NULL_BAG_SCHEMA_NAME, ne, addBinary, elementType, StructScalaType, index, addFloat)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala: Set(isPrimitive, map, MAP_SCHEMA_NAME, asInstanceOf, isInstanceOf, <init>, schema, CatalystConverter, MAP_KEY_SCHEMA_NAME, MAP_VALUE_SCHEMA_NAME, ==, ARRAY_ELEMENTS_SCHEMA_NAME, toString, !=, getClass, ARRAY_CONTAINS_NULL_BAG_SCHEMA_NAME, converter, ne, elementType, eq)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, DateColumnBuilder, BasicColumnBuilder, ByteColumnBuilder, wait, ColumnBuilder, apply$default$4, GenericColumnBuilder, $asInstanceOf, columnName, equals, NativeColumnBuilder, StringColumnBuilder, gatherCompressibilityStats, asInstanceOf, columnStats, log_, pos, synchronized, isWorthCompressing, $isInstanceOf, apply$default$3, IntColumnBuilder, build, buffer, logTrace, BooleanColumnBuilder, nulls, isTraceEnabled, super$appendFrom, columnType, initialize$default$3, logName, notifyAll, schemes, initialize, isInstanceOf, ShortColumnBuilder, <init>, FloatColumnBuilder, super$build, apply$default$2, apply, ==, clone, compressionEncoders, BinaryColumnBuilder, appendFrom, ensureFreeSpace, toString, initialize$default$2, logError, !=, DoubleColumnBuilder, getClass, logWarning, TimestampColumnBuilder, initializeIfNecessary, buildNonNulls, ComplexColumnBuilder, nullCount, LongColumnBuilder, ne, DEFAULT_INITIAL_BUFFER_SIZE, eq, log, super$initialize, ##, finalize, hashCode, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(ColumnBuilder, columnName, NativeColumnBuilder, gatherCompressibilityStats, isWorthCompressing, nulls, super$appendFrom, columnType, schemes, apply, ==, compressionEncoders, buildNonNulls, nullCount, super$initialize, logDebug)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala: Set(ColumnBuilder, columnName, columnStats, pos, buffer, nulls, super$appendFrom, super$build, ensureFreeSpace, nullCount, super$initialize)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(ColumnBuilder, asInstanceOf, columnStats, build, columnType, isInstanceOf, <init>, apply, ==, appendFrom, toString, nullCount, ne, eq, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(ColumnBuilder, columnName, NativeColumnBuilder, gatherCompressibilityStats, isWorthCompressing, nulls, super$appendFrom, columnType, schemes, apply, ==, compressionEncoders, buildNonNulls, nullCount, super$initialize, logDebug)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(DateColumnBuilder, BasicColumnBuilder, ByteColumnBuilder, ColumnBuilder, GenericColumnBuilder, columnName, NativeColumnBuilder, StringColumnBuilder, asInstanceOf, columnStats, pos, IntColumnBuilder, buffer, BooleanColumnBuilder, columnType, initialize, ShortColumnBuilder, <init>, FloatColumnBuilder, ==, BinaryColumnBuilder, ensureFreeSpace, DoubleColumnBuilder, TimestampColumnBuilder, ComplexColumnBuilder, LongColumnBuilder, DEFAULT_INITIAL_BUFFER_SIZE)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(DateColumnBuilder, BasicColumnBuilder, ByteColumnBuilder, ColumnBuilder, GenericColumnBuilder, columnName, NativeColumnBuilder, StringColumnBuilder, asInstanceOf, columnStats, pos, IntColumnBuilder, buffer, BooleanColumnBuilder, columnType, initialize, ShortColumnBuilder, <init>, FloatColumnBuilder, ==, BinaryColumnBuilder, ensureFreeSpace, DoubleColumnBuilder, TimestampColumnBuilder, ComplexColumnBuilder, LongColumnBuilder, DEFAULT_INITIAL_BUFFER_SIZE)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF7.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF7.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF7.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF7.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF7.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF7.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF7.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF7)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF17.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF17.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF17.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF17.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF17.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF17.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF17.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF17)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/filters.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/filters.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/filters.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/filters.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/filters.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, GreaterThan, wait, copy$default$2, $asInstanceOf, In, productArity, equals, asInstanceOf, synchronized, $isInstanceOf, canEqual, productPrefix, notifyAll, GreaterThanOrEqual, isInstanceOf, LessThan, <init>, ==, clone, LessThanOrEqual, copy, values, toString, !=, attribute, getClass, copy$default$1, EqualTo, Filter, ne, value, eq, productIterator, ##, finalize, productElement, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, Filter, value)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala: Set(<init>, Filter)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	testNestedDir1, notify, groupWriter, writeNestedFile4, testSchemaFieldNames, testSchema, testNestedSchema1, wait, $asInstanceOf, testGlobDir, writeFilterFile, testNestedData2, equals, asInstanceOf, ParquetTestData, testFilterDir, synchronized, $isInstanceOf, testNestedDir2, testNestedSchema2, testNestedData1, notifyAll, finalizeWrite, writeGlobFiles, testGlobSubDir3, isInstanceOf, subTestSchemaFieldNames, writeNestedFile2, testNestedSchema4, <init>, testDir, TestGroupWriteSupport, writeFile, testGlobSubDir2, testNestedDir3, writeFilterFile$default$1, testData, ==, clone, writeNestedFile3, toString, !=, getClass, testGlobSubDir1, testFilterSchema, subTestSchema, prepareForWrite, writeNestedFile1, testNestedDir4, ne, init, testNestedSchema3, eq, write, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, convertCatalystToJava, wait, $asInstanceOf, asScalaStructField, equals, asJavaStructField, DataTypeConversions, convertJavaToCatalyst, asInstanceOf, stringToTime, synchronized, $isInstanceOf, notifyAll, isInstanceOf, ==, clone, asScalaDataType, asJavaDataType, toString, !=, getClass, ne, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(DataTypeConversions, convertJavaToCatalyst, asInstanceOf, ==, asScalaDataType, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala: Set(DataTypeConversions, asInstanceOf, isInstanceOf, asScalaDataType, asJavaDataType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JsonRDD.scala: Set(DataTypeConversions, asInstanceOf, stringToTime, isInstanceOf, ==, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(DataTypeConversions, asInstanceOf, asJavaDataType, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(DataTypeConversions, asInstanceOf, asScalaDataType)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, isContainsNull, wait, equals, LongType, IntegerType, TimestampType, ArrayType, notifyAll, DoubleType, <init>, containsNull, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, elementType, getElementType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, isContainsNull, LongType, IntegerType, TimestampType, ArrayType, DoubleType, <init>, containsNull, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, elementType, getElementType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, HashJoin, $asInstanceOf, buildSideKeyGenerator, hashJoin, equals, buildSide, x$2, streamedPlan, asInstanceOf, synchronized, left, $isInstanceOf, x$1, buildPlan, notifyAll, isInstanceOf, leftKeys, rightKeys, ==, clone, buildKeys, $init$, streamSideKeyGenerator, toString, !=, getClass, streamedKeys, output, ne, eq, right, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(HashJoin, hashJoin, buildSide, asInstanceOf, left, isInstanceOf, leftKeys, rightKeys, ==, toString, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(HashJoin, hashJoin, buildSide, asInstanceOf, left, isInstanceOf, leftKeys, rightKeys, ==, toString, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(HashJoin, hashJoin, buildSide, asInstanceOf, left, isInstanceOf, leftKeys, rightKeys, ==, toString, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(HashJoin, hashJoin, buildSide, asInstanceOf, left, isInstanceOf, leftKeys, rightKeys, ==, toString, output, ne, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala: Set(HashJoin, buildSideKeyGenerator, buildSide, streamedPlan, asInstanceOf, left, buildPlan, isInstanceOf, leftKeys, rightKeys, ==, streamSideKeyGenerator, toString, output, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala: Set(HashJoin, buildSideKeyGenerator, hashJoin, buildSide, streamedPlan, asInstanceOf, left, buildPlan, isInstanceOf, leftKeys, rightKeys, ==, toString, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala: Set(HashJoin, buildSideKeyGenerator, buildSide, x$2, streamedPlan, asInstanceOf, left, buildPlan, isInstanceOf, leftKeys, rightKeys, ==, streamSideKeyGenerator, toString, output, eq, right)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala: Set(HashJoin, buildSideKeyGenerator, hashJoin, buildSide, streamedPlan, asInstanceOf, left, buildPlan, isInstanceOf, leftKeys, rightKeys, ==, toString, eq, right)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, decoder, wait, $asInstanceOf, equals, columnHeaderSize, all, gatherCompressibilityStats, asInstanceOf, synchronized, $isInstanceOf, typeId, Encoder, notifyAll, schemes, WithCompressionSchemes, typeIdToScheme, AllCompressionSchemes, isInstanceOf, compressedSize, uncompressedSize, encoder, apply, supports, ==, compressionRatio, clone, compress, $init$, next, Decoder, toString, !=, getClass, ne, hasNext, eq, CompressionScheme, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(gatherCompressibilityStats, typeId, Encoder, schemes, WithCompressionSchemes, compressedSize, encoder, apply, supports, ==, compressionRatio, compress)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(asInstanceOf, typeId, AllCompressionSchemes, ==)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala: Set(decoder, apply, next, Decoder, hasNext, CompressionScheme)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(gatherCompressibilityStats, typeId, Encoder, schemes, WithCompressionSchemes, compressedSize, encoder, apply, supports, ==, compressionRatio, compress)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala: Set(asInstanceOf, typeId, Encoder, apply, ==, clone, Decoder, toString, !=, CompressionScheme)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(asInstanceOf, typeId, AllCompressionSchemes, ==)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(gatherCompressibilityStats, typeId, Encoder, schemes, WithCompressionSchemes, compressedSize, encoder, apply, supports, ==, compressionRatio, compress)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala: Set(typeId)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(asInstanceOf, typeId, isInstanceOf, apply, ==, next, toString, ne, hasNext, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(asInstanceOf, typeId, AllCompressionSchemes, ==)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala: Set(all, typeId, Encoder, schemes, WithCompressionSchemes, typeIdToScheme, AllCompressionSchemes, compressedSize, uncompressedSize, apply, Decoder, CompressionScheme)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(gatherCompressibilityStats, typeId, Encoder, schemes, WithCompressionSchemes, compressedSize, encoder, apply, supports, ==, compressionRatio, compress)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF2.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF2.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF2.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF2.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF2.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF2.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF2)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF2.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetRelation.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, unapply, simpleString, children, createEmpty, resolveNesting, wait, apply$default$4, copy$default$2, $asInstanceOf, path, numberedTreeString, printSchema, map, productArity, equals, statistics, treeString, transformChildrenDown, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, childrenResolved, log_, synchronized, nodeName, $isInstanceOf, create, <init>$default$4, enableLogForwarding, checkPath, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, RowType, ParquetRelation, productPrefix, resolveChildren, cleanArgs, logName, notifyAll, readResolve, conf, CompressionType, otherCopyArgs, missingInput, isInstanceOf, stringArgs, references, partitioningAttributes, parquetSchema, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, resolved, ==, fastEquals, sqlContext, transformExpressionsUp, clone, sameResult, foreach, resolve, newInstance, copy$default$3, copy, inputSet, toString, logError, !=, collect, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, statePrefix, eq, productIterator, log, ##, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, shortParquetCompressionCodecNames, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala: Set(path, map, asInstanceOf, expressions, ParquetRelation, conf, isInstanceOf, partitioningAttributes, parquetSchema, <init>, schema, apply, flatMap, ==, sqlContext, foreach, toString, !=, getClass, output, ne, eq, log, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(createEmpty, path, map, asInstanceOf, expressions, ParquetRelation, conf, <init>, schema, apply, ==, sqlContext, newInstance, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala: Set(unapply, children, path, map, asInstanceOf, enableLogForwarding, expressions, ParquetRelation, conf, isInstanceOf, parquetSchema, <init>, schema, apply, flatMap, ==, foreach, toString, !=, getClass, ne, eq, log)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTestData.scala: Set(path, ParquetRelation, conf, <init>, schema, apply, ==, foreach, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala: Set(map, schemaString, asInstanceOf, enableLogForwarding, expressions, ParquetRelation, conf, isInstanceOf, parquetSchema, <init>, schema, apply, ==, foreach, toString, !=, ne, log)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(createEmpty, path, map, schemaString, asInstanceOf, expressions, ParquetRelation, conf, isInstanceOf, references, <init>, schema, apply, flatMap, ==, sqlContext, foreach, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(unapply, path, map, statistics, asInstanceOf, create, expressions, ParquetRelation, isInstanceOf, <init>, apply, flatMap, ==, sqlContext, toString, collect, output, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableSupport.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, setSchema, writeMap, wait, SPARK_ROW_SCHEMA, $asInstanceOf, writer, equals, getCurrentRecord, asInstanceOf, MutableRowWriteSupport, log_, getSchema, RowRecordMaterializer, synchronized, $isInstanceOf, logTrace, isTraceEnabled, SPARK_METADATA_KEY, logName, notifyAll, attributes, finalizeWrite, writePrimitive, isInstanceOf, prepareForRead, writeArray, <init>, consumeType, writeDecimal, skipCurrentRecord, writeValue, ==, getRootConverter, clone, writeStruct, toString, RowReadSupport, logError, !=, SPARK_ROW_REQUESTED_SCHEMA, getClass, logWarning, initializeIfNecessary, prepareForWrite, scratchBytes, ne, init, eq, write, log, RowWriteSupport, getRequestedSchema, ##, finalize, hashCode, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTypes.scala: Set(asInstanceOf, getSchema, SPARK_METADATA_KEY, attributes, isInstanceOf, <init>, ==, toString, RowReadSupport, !=, getClass, ne, eq, log)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala: Set(setSchema, SPARK_ROW_SCHEMA, writer, asInstanceOf, getSchema, attributes, isInstanceOf, <init>, ==, toString, RowReadSupport, !=, SPARK_ROW_REQUESTED_SCHEMA, getClass, ne, init, eq, write, log, RowWriteSupport, getRequestedSchema, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(SPARK_ROW_SCHEMA, asInstanceOf, isInstanceOf, <init>, ==, toString, RowReadSupport, !=, SPARK_ROW_REQUESTED_SCHEMA, ne, eq, RowWriteSupport, logInfo)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, ruleName, simpleString, children, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, printSchema, map, productArity, equals, treeString, transformChildrenDown, schemaString, argString, newPartitioning, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, codegenEnabled, nodeName, $isInstanceOf, Exchange, logTrace, asCode, canEqual, expressions, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, bypassMergeThreshold, otherCopyArgs, missingInput, isInstanceOf, stringArgs, child, references, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, sparkContext, outputPartitioning, copy, inputSet, toString, AddExchange, logError, !=, collect, getClass, sortBasedShuffleOn, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, newProjection, statePrefix, numPartitions, eq, productIterator, log, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, codegenEnabled, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, numPartitions)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(execute, map, schemaString, asInstanceOf, codegenEnabled, expressions, isInstanceOf, references, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF20.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF20.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF20.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF20.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF20.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF20.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF20)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF20.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF11.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF11.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF11.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF11.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF11.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF11.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF11.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF11)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkSqlSerializer.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkSqlSerializer.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkSqlSerializer.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkSqlSerializer.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkSqlSerializer.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	KryoResourcePool, notify, read, ser, setAcceptsNull, getAcceptsNull, newKryoOutput, OpenHashSetSerializer, wait, $asInstanceOf, equals, BigDecimalSerializer, referenceTracking, setImmutable, asInstanceOf, log_, resourcePool, synchronized, $isInstanceOf, classesToRegister, logTrace, setGenerics, isTraceEnabled, deserialize, registrationRequired, userRegistrator, logName, borrow, notifyAll, readResolve, isInstanceOf, defaultClassLoader, <init>, setDefaultClassLoader, LongHashSetSerializer, ==, newKryo, clone, maxBufferSize, bufferSize, HyperLogLogSerializer, newInstance, copy, IntegerHashSetSerializer, toString, logError, !=, isImmutable, release, getClass, logWarning, initializeIfNecessary, ne, serialize, eq, write, SparkSqlSerializer, log, ##, finalize, hashCode, logDebug, acquireRelease, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnType.scala: Set(asInstanceOf, deserialize, <init>, ==, getClass, serialize, SparkSqlSerializer)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, copy, toString, eq, SparkSqlSerializer)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, copy, toString, !=, ne, eq, SparkSqlSerializer, logDebug)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	dataSchema, notify, discoverPartitions, wait, copy$default$2, $asInstanceOf, path, productArity, equals, buildScan, asInstanceOf, dataIncludesKey, log_, DefaultSource, synchronized, $isInstanceOf, logTrace, canEqual, isTraceEnabled, productPrefix, logName, files, notifyAll, isInstanceOf, <init>, schema, ==, sqlContext, clone, sparkContext, sizeInBytes, Partition, copy, toString, createRelation, logError, !=, partitions, getClass, logWarning, copy$default$1, initializeIfNecessary, partitionValues, ne, partitionKeys, ParquetRelation2, eq, productIterator, log, ##, finalize, productElement, hashCode, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, PrunedScan, wait, $asInstanceOf, equals, buildScan, asInstanceOf, synchronized, $isInstanceOf, notifyAll, isInstanceOf, BaseRelation, <init>, schema, ==, CatalystScan, sqlContext, clone, sizeInBytes, RelationProvider, TableScan, toString, createRelation, !=, getClass, ne, PrunedFilteredScan, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/ddl.scala: Set(asInstanceOf, isInstanceOf, <init>, ==, sqlContext, RelationProvider, toString, createRelation, getClass, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(asInstanceOf, BaseRelation, <init>, schema, ==, sqlContext, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(asInstanceOf, isInstanceOf, BaseRelation, <init>, schema, ==, CatalystScan, sqlContext, sizeInBytes, RelationProvider, toString, !=, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala: Set(buildScan, asInstanceOf, isInstanceOf, <init>, ==)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/LogicalRelation.scala: Set(asInstanceOf, isInstanceOf, BaseRelation, <init>, schema, ==, sizeInBytes, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala: Set(asInstanceOf, isInstanceOf, BaseRelation, <init>, schema, ==, sqlContext, RelationProvider, TableScan, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(asInstanceOf, isInstanceOf, BaseRelation, <init>, schema, ==, sqlContext, toString, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	zipPartitions, notify, mapPartitionsWithIndex$default$2, mapPartitionsToPair, unpersist, wrapRDD, coalesce, name, schemaRDD, count, wait, saveAsParquetFile, $asInstanceOf, mapPartitions, setName, insertInto, zip, printSchema, mapToPair, map, subtract, equals, intersection, schemaString, mapPartitionsToDouble, flatMapToPair, foreachPartition, asInstanceOf, context, foreachAsync, glom, takeAsync, synchronized, aggregate, $isInstanceOf, min, getCheckpointFile, countAsync, fold, zipWithUniqueId, iterator, countApprox, notifyAll, cache, baseLogicalPlan, isInstanceOf, foreachPartitionAsync, filter, registerAsTable, rdd, unpersist$default$1, super$toString, persist, classTag, <init>, isCheckpointed, id, countApproxDistinct, schema, max, splits, toDebugString, flatMap, take, baseSchemaRDD, groupBy, ==, sqlContext, clone, distinct, foreach, toLocalIterator, flatMapToDouble, toArray, reduce, saveAsTextFile, collectAsync, zipWithIndex, getStorageLevel, checkpoint, first, countByValue, sample, toString, !=, partitions, collect, getClass, pipe, saveAsTable, JavaSchemaRDD, mapToDouble, cartesian, repartition, queryExecution, collectPartitions, ne, countByValueApprox, mapPartitionsWithIndex, keyBy, top, coalesce$default$2, registerTempTable, saveAsObjectFile, eq, toJSON, logicalPlan, ##, finalize, hashCode, takeOrdered, takeSample.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(coalesce, name, mapPartitions, map, subtract, intersection, asInstanceOf, context, aggregate, baseLogicalPlan, isInstanceOf, filter, rdd, <init>, schema, groupBy, sqlContext, distinct, toArray, zipWithIndex, toString, partitions, collect, JavaSchemaRDD, repartition, queryExecution, ne, logicalPlan, takeSample)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(mapPartitions, zip, map, asInstanceOf, rdd, <init>, schema, baseSchemaRDD, ==, sqlContext, toArray, JavaSchemaRDD, ne, logicalPlan)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, fields, DateType, createMapType, toString, getFields, getClass, StructType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(StringType, LongType, IntegerType, TimestampType, DoubleType, <init>, fields, DateType, StructType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(<init>, toString, StructType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, fields, DateType, createMapType, getFields, StructType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF9.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF9.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF9.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF9.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF9.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	UDF9, call.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(UDF9, call)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF9.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/Metadata.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/Metadata.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/Metadata.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/Metadata.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/Metadata.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, Metadata, wait, getMetadata, empty, map, equals, json, getDoubleArray, getDouble, getString, notifyAll, getLongArray, <init>, toString, fromJson, getBoolean, getMetadataArray, getClass, contains, getStringArray, getBooleanArray, jsonValue, getLong, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/Metadata.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MetadataBuilder.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, sql, createParquetFile, wait, $asInstanceOf, createParquetFile$default$4, equals, asInstanceOf, registerRDDAsTable, jsonRDD, getSchema, synchronized, $isInstanceOf, parquetFile, jsonFile, notifyAll, isInstanceOf, baseRelationToSchemaRDD, <init>, registerFunction, ==, sqlContext, createParquetFile$default$3, clone, applySchema, toString, !=, getClass, ne, eq, ##, finalize, JavaSQLContext, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(sql, asInstanceOf, registerFunction, sqlContext, JavaSQLContext)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashOuterJoin.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, fullOuterIterator, rightNullRow, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, copy$default$5, printSchema, leftOuterIterator, map, productArity, equals, treeString, transformChildrenDown, leftNullRow, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, left, codegenEnabled, nodeName, $isInstanceOf, boundCondition, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, buildHashTable, otherCopyArgs, missingInput, isInstanceOf, stringArgs, leftKeys, rightKeys, references, <init>, mapChildren, condition, schema, transformExpressionsDown, apply, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, HashOuterJoin, newMutableProjection, newPredicate, foreach, sparkContext, outputPartitioning, DUMMY_LIST, copy$default$3, copy, inputSet, toString, logError, !=, collect, joinType, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, rightOuterIterator, copy$default$6, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, right, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, EMPTY_LIST, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, expressions, isInstanceOf, leftKeys, rightKeys, <init>, condition, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, joinType, output, ne, right)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/package.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/package.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/package.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/package.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/package.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, Metadata, Row, NullType, package, wait, $asInstanceOf, equals, LongType, asInstanceOf, IntegerType, synchronized, $isInstanceOf, TimestampType, ArrayType, notifyAll, Strategy, isInstanceOf, DoubleType, ==, clone, DateType, toString, !=, MetadataBuilder, getClass, StructType, BinaryType, DecimalType, BooleanType, ne, DataType, ByteType, eq, StructField, FloatType, ##, finalize, hashCode, ShortType, MapType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/ExistingRDD.scala: Set(Row, package, asInstanceOf, isInstanceOf, ==, toString, StructType, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(StringType, Row, package, LongType, asInstanceOf, IntegerType, TimestampType, DoubleType, ==, DateType, StructType, DecimalType, BooleanType, ne, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala: Set(package, asInstanceOf, isInstanceOf, DataType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala: Set(Row, package)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala: Set(package)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(StringType, Row, package, asInstanceOf, IntegerType, isInstanceOf, ==, toString, !=, StructType, ne, eq, StructField)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/DataSourceStrategy.scala: Set(Row, package, asInstanceOf, Strategy, isInstanceOf, ==)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(Row, package, asInstanceOf, isInstanceOf, ==, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala: Set(Row, package, StructType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(Row, package, asInstanceOf, toString, StructType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(package, asInstanceOf, DataType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(Row, package, asInstanceOf, isInstanceOf, toString, StructType, BooleanType, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, package, LongType, asInstanceOf, IntegerType, TimestampType, ArrayType, isInstanceOf, DoubleType, ==, DateType, MetadataBuilder, StructType, BinaryType, DecimalType, BooleanType, ne, DataType, ByteType, StructField, FloatType, ShortType, MapType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnStats.scala: Set(Row, package, LongType, asInstanceOf, IntegerType, ==, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(Row, package, asInstanceOf, TimestampType, Strategy, isInstanceOf, ==, DateType, toString, StructType, ne, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala: Set(Row, package)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Exchange.scala: Set(Row, package, asInstanceOf, isInstanceOf, ==, toString, !=, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala: Set(StringType, Row, package, LongType, asInstanceOf, IntegerType, isInstanceOf, DoubleType, ==, toString, !=, getClass, BooleanType, ne, DataType, ByteType, eq, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(Row, package, asInstanceOf, ==, DataType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnType.scala: Set(StringType, Row, package, LongType, asInstanceOf, IntegerType, TimestampType, DoubleType, ==, DateType, getClass, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(Row, package, LongType, asInstanceOf, IntegerType, Strategy, isInstanceOf, ==, toString, StructType, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(Row, package, ==)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala: Set(Row, package, asInstanceOf, ==, clone, toString, !=)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/pythonUdfs.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, unapply, ruleName, nullable, n2, simpleString, children, name, resolveNesting, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, copy$default$5, printSchema, map, productArity, equals, statistics, treeString, transformChildrenDown, schemaString, copy$default$9, ExtractPythonUdfs, argString, f1, asInstanceOf, transformExpressions, n1, generateTreeString, childrenResolved, log_, BatchPythonEvaluation, synchronized, PythonUDF, EvaluatedType, codegenEnabled, nodeName, $isInstanceOf, copy$default$8, c2, envVars, logTrace, asCode, EvaluatePython, canEqual, expressions, copy$default$4, broadcastVars, outputSet, isTraceEnabled, makeCopy, pythonIncludes, transformUp, command, rowToArray, productPrefix, resolveChildren, cleanArgs, logName, notifyAll, readResolve, otherCopyArgs, missingInput, isInstanceOf, eval, stringArgs, child, references, toJava, <init>, i1, mapChildren, pythonExec, schema, transformExpressionsDown, apply, flatMap, resolved, executeCollect, ==, fastEquals, sqlContext, accumulator, transformExpressionsUp, clone, newMutableProjection, newPredicate, sameResult, foreach, udf, copy$default$7, resolve, sparkContext, outputPartitioning, resultAttribute, i2, copy$default$3, copy, inputSet, toString, logError, !=, collect, getClass, logWarning, output, copy$default$1, dataType, foldable, initializeIfNecessary, transformDown, transformAllExpressions, copy$default$6, ne, eval$default$1, transform, fromJava, withNewChildren, newProjection, statePrefix, eq, productIterator, log, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, f2, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala: Set(name, map, asInstanceOf, EvaluatePython, expressions, rowToArray, isInstanceOf, <init>, schema, apply, executeCollect, sqlContext, udf, sparkContext, toString, collect, output, dataType, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(unapply, map, statistics, asInstanceOf, codegenEnabled, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, udf, sparkContext, toString, collect, output, dataType, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/UdfRegistration.scala: Set(name, PythonUDF, envVars, expressions, broadcastVars, pythonIncludes, command, pythonExec, accumulator, dataType, log)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(execute, map, schemaString, ExtractPythonUdfs, asInstanceOf, codegenEnabled, EvaluatePython, expressions, isInstanceOf, references, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, dataType, ne, fromJava)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDD.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	creationSite, zipPartitions, markCheckpointed, notify, mapPartitionsWithIndex$default$2, unpersist, sortBy$default$2, generate$default$4, parent, distinct$default$2, partitioner, mapPartitionsWithSplit, coalesce, name, count, wait, saveAsParquetFile, toJavaSchemaRDD, $asInstanceOf, mapPartitions, setName, insertInto, union, intersect, coalesce$default$3, filterWith, zip, printSchema, join, map, subtract, equals, pipe$default$5, intersection, schemaString, sortBy$default$3, foreachPartition, countApprox$default$2, generate, flatMapWith$default$2, asInstanceOf, context, subtract$default$3, getPreferredLocations, glom, log_, sortBy, doCheckpoint, synchronized, pipe$default$2, repartition$default$2, sc, collectToPython, aggregate, $isInstanceOf, compute, as, mapPartitions$default$2, min, getCheckpointFile, generate$default$3, fold, logTrace, partitions_, isTraceEnabled, sample$default$1, zipWithUniqueId, iterator, doCheckpointCalled, mapPartitionsWithContext, countApprox, logName, notifyAll, countApproxDistinct$default$1, conf, unionAll, getNarrowAncestors, generate$default$2, mapPartitionsWithSplit$default$2, cache, baseLogicalPlan, isInstanceOf, filter, registerAsTable, select, pipe$default$3, countByValueApprox$default$3, unpersist$default$1, super$toString, persist, checkpointData, <init>, isCheckpointed, id, countApproxDistinct, schema, join$default$3, max, toDebugString, ++, flatMap, take, countByValue$default$1, baseSchemaRDD, deps, groupBy, ==, toSchemaRDD, checkpointRDD, sqlContext, mapWith, randomSplit$default$2, groupBy$default$4, clone, distinct, retag, foreach, javaToPython, orderBy, toLocalIterator, sparkContext, toArray, reduce, SchemaRDD, saveAsTextFile, takeSample$default$3, zipWithIndex, takeSampleToPython, getStorageLevel, checkpoint, first, countByValue, countByValueApprox$default$2, applySchema, elementClassTag, sample, toString, preferredLocations, logError, !=, where, partitions, collect, flatMapWith, getClass, pipe, logWarning, getPartitions, initializeIfNecessary, saveAsTable, pipe$default$4, cartesian, repartition, queryExecution, collectPartitions, mapPartitionsWithContext$default$2, mapWith$default$2, clearDependencies, sample$default$3, except, ne, limit, countByValueApprox, getDependencies, mapPartitionsWithIndex, intersection$default$3, keyBy, randomSplit, top, coalesce$default$2, foreachWith, getCreationSite, computeOrReadCheckpoint, registerTempTable, dependencies, dependencies_, saveAsObjectFile, join$default$2, toJavaRDD, eq, toJSON, storageLevel, log, logicalPlan, ##, finalize, hashCode, takeOrdered, logDebug, firstParent, logInfo, takeSample, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SchemaRDDLike.scala: Set(insertInto, schemaString, baseLogicalPlan, isInstanceOf, super$toString, schema, baseSchemaRDD, sqlContext, SchemaRDD, queryExecution, registerTempTable, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/CacheManager.scala: Set(unpersist, map, asInstanceOf, isInstanceOf, <init>, ==, foreach, SchemaRDD, toString, collect, logWarning, queryExecution, eq, storageLevel)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(unpersist, partitioner, coalesce, name, count, toJavaSchemaRDD, setName, map, subtract, intersection, asInstanceOf, cache, baseLogicalPlan, filter, persist, <init>, schema, take, baseSchemaRDD, sqlContext, distinct, SchemaRDD, sample, toString, collect, repartition, toJavaRDD, toJSON, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/SQLContext.scala: Set(mapPartitions, zip, map, schemaString, asInstanceOf, conf, isInstanceOf, <init>, schema, ++, flatMap, ==, sqlContext, foreach, sparkContext, SchemaRDD, applySchema, toString, queryExecution, ne, logicalPlan)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/debug/package.scala: Set(name, count, mapPartitions, zip, map, asInstanceOf, isInstanceOf, <init>, schema, ==, foreach, sparkContext, SchemaRDD, toString, !=, getClass, queryExecution, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTest.scala: Set(saveAsParquetFile, zip, map, asInstanceOf, isInstanceOf, <init>, ==, sqlContext, foreach, sparkContext, SchemaRDD, ne, registerTempTable)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/commands.scala: Set(unpersist, name, count, map, asInstanceOf, isInstanceOf, <init>, ==, sqlContext, foreach, sparkContext, toArray, toString, logWarning, queryExecution, ne, registerTempTable, eq, logicalPlan)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/json/JSONRelation.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, copy$default$2, $asInstanceOf, JSONRelation, productArity, equals, buildScan, asInstanceOf, DefaultSource, synchronized, $isInstanceOf, fileName, canEqual, productPrefix, notifyAll, isInstanceOf, baseRDD, <init>, schema, ==, sqlContext, clone, samplingRatio, sizeInBytes, copy, toString, createRelation, !=, getClass, copy$default$1, ne, eq, productIterator, ##, finalize, productElement, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF5.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF5.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF5.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF5.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF5.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF5.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF5)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF5.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, copy$default$5, printSchema, buildSideKeyGenerator, map, hashJoin, productArity, equals, treeString, transformChildrenDown, ShuffledHashJoin, buildSide, schemaString, argString, streamedPlan, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, left, codegenEnabled, nodeName, $isInstanceOf, buildPlan, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, leftKeys, rightKeys, references, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, buildKeys, sparkContext, outputPartitioning, copy$default$3, copy, inputSet, streamSideKeyGenerator, toString, logError, !=, collect, getClass, streamedKeys, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, right, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, hashJoin, buildSide, asInstanceOf, left, codegenEnabled, expressions, isInstanceOf, leftKeys, rightKeys, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Aggregate.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, unapply, curried, simpleString, newAggregateBuffer, Aggregate, children, execute, wait, childOutput, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, partial, printSchema, map, productArity, resultExpressions, equals, treeString, transformChildrenDown, namedGroups, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, ComputedAggregate, codegenEnabled, nodeName, aggregate, $isInstanceOf, tupled, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, readResolve, otherCopyArgs, missingInput, isInstanceOf, stringArgs, child, references, <init>, mapChildren, schema, groupingExpressions, transformExpressionsDown, apply, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, computedAggregates, foreach, unbound, sparkContext, outputPartitioning, resultAttribute, copy$default$3, copy, inputSet, toString, logError, !=, aggregateExpressions, collect, getClass, logWarning, resultMap, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, ##, computedSchema, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(unapply, map, asInstanceOf, codegenEnabled, expressions, isInstanceOf, child, <init>, groupingExpressions, apply, flatMap, ==, sqlContext, sparkContext, toString, aggregateExpressions, collect, output, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF13.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF13.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF13.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF13.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF13.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	UDF13, call.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF13.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(UDF13, call)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, deserialize, notifyAll, DoubleType, <init>, userClass, createStructField, DateType, createMapType, toString, sqlType, getClass, UserDefinedType, createArrayType, BinaryType, BooleanType, serialize, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, UserDefinedType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala: Set(deserialize, <init>, userClass, sqlType, UserDefinedType, serialize)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, UserDefinedType, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/DiskHashedRelation.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/DiskHashedRelation.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/DiskHashedRelation.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/DiskHashedRelation.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/DiskHashedRelation.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	spillPartitionToDisk, inStream, notify, wait, closeAllPartitions, apply$default$4, $asInstanceOf, path, insert, equals, asInstanceOf, DiskHashedRelation, data, synchronized, $isInstanceOf, inputClosed, apply$default$3, DiskPartition, notifyAll, isInstanceOf, <init>, outStream, getData, apply, measurePartitionSize, ==, clone, chunkSizes, toString, !=, getClass, closeInput, ne, GeneralDiskHashedRelation, closePartition, writtenToDisk, eq, ##, finalize, getIterator, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/GeneratedAggregate.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, partial, printSchema, map, productArity, equals, treeString, transformChildrenDown, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, result, log_, synchronized, codegenEnabled, nodeName, $isInstanceOf, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, child, references, <init>, mapChildren, schema, groupingExpressions, transformExpressionsDown, apply, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, sparkContext, outputPartitioning, copy$default$3, copy, inputSet, initialValues, toString, AggregateEvaluation, logError, !=, aggregateExpressions, collect, getClass, logWarning, output, copy$default$1, update, initializeIfNecessary, transformDown, transformAllExpressions, GeneratedAggregate, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, codegenEnabled, expressions, isInstanceOf, child, <init>, groupingExpressions, apply, flatMap, ==, sqlContext, sparkContext, toString, aggregateExpressions, collect, output, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinBNL.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, printSchema, map, productArity, equals, treeString, transformChildrenDown, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, left, codegenEnabled, nodeName, $isInstanceOf, streamed, boundCondition, logTrace, asCode, canEqual, expressions, LeftSemiJoinBNL, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, references, <init>, mapChildren, condition, schema, transformExpressionsDown, apply, broadcast, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, sparkContext, outputPartitioning, copy$default$3, copy, inputSet, toString, logError, !=, collect, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, right, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, asInstanceOf, left, codegenEnabled, expressions, isInstanceOf, <init>, condition, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, keyType, createStructType, wait, equals, LongType, IntegerType, valueType, getValueType, TimestampType, notifyAll, isValueContainsNull, DoubleType, <init>, getKeyType, createStructField, DateType, createMapType, valueContainsNull, toString, getClass, createArrayType, BinaryType, BooleanType, ByteType, FloatType, hashCode, ShortType, MapType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, keyType, createStructType, LongType, IntegerType, valueType, getValueType, TimestampType, isValueContainsNull, DoubleType, <init>, getKeyType, createStructField, DateType, createMapType, valueContainsNull, createArrayType, BinaryType, BooleanType, ByteType, FloatType, ShortType, MapType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/package.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/package.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/package.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/package.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/package.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, package, wait, $asInstanceOf, equals, asInstanceOf, synchronized, $isInstanceOf, notifyAll, isInstanceOf, ==, clone, toString, !=, getClass, ne, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/Row.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/Row.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/Row.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/Row.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/Row.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, Row, getShort, wait, $asInstanceOf, toJavaValue, equals, isNullAt, asInstanceOf, getDouble, getString, synchronized, $isInstanceOf, create, toScalaValue, canEqual, row, notifyAll, readResolve, getByte, isInstanceOf, <init>, getFloat, ==, clone, getInt, toString, getBoolean, length, !=, get, getClass, ne, eq, ##, finalize, getLong, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(Row, asInstanceOf, row, <init>, ==, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(Row, asInstanceOf, <init>, toString)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, BroadcastHashJoin, simpleString, children, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, copy$default$5, printSchema, buildSideKeyGenerator, map, hashJoin, productArity, equals, treeString, transformChildrenDown, buildSide, schemaString, argString, streamedPlan, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, left, codegenEnabled, nodeName, $isInstanceOf, buildPlan, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, leftKeys, rightKeys, references, broadcastFuture, <init>, mapChildren, schema, transformExpressionsDown, apply, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, buildKeys, sparkContext, outputPartitioning, copy$default$3, copy, inputSet, streamSideKeyGenerator, toString, logError, !=, collect, getClass, streamedKeys, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, timeout, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, right, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, hashJoin, buildSide, asInstanceOf, left, codegenEnabled, expressions, isInstanceOf, leftKeys, rightKeys, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne, right)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/ExamplePointUDT.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/ExamplePointUDT.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/ExamplePointUDT.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/ExamplePointUDT.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/test/ExamplePointUDT.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, unapply, x, isPrimitive, wait, $asInstanceOf, equals, json, y, asInstanceOf, synchronized, $isInstanceOf, deserialize, typeName, notifyAll, ExamplePoint, isInstanceOf, <init>, prettyJson, userClass, ==, clone, pyUDT, toString, !=, sqlType, getClass, ne, serialize, jsonValue, eq, ##, finalize, hashCode, ExamplePointUDT.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/package.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/package.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/package.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/package.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/package.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, package, wait, $asInstanceOf, BuildRight, productArity, equals, asInstanceOf, synchronized, $isInstanceOf, canEqual, BuildSide, productPrefix, notifyAll, readResolve, isInstanceOf, BuildLeft, <init>, ==, clone, toString, !=, getClass, ne, eq, productIterator, ##, finalize, productElement, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala: Set(package, BuildRight, asInstanceOf, BuildSide, isInstanceOf, BuildLeft, <init>, ==, toString, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/LeftSemiJoinHash.scala: Set(package, BuildRight, asInstanceOf, isInstanceOf, <init>, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala: Set(package, asInstanceOf, BuildSide, isInstanceOf, <init>, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(package, BuildRight, asInstanceOf, BuildSide, isInstanceOf, BuildLeft, <init>, ==, toString, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala: Set(package, asInstanceOf, BuildSide, isInstanceOf, <init>, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastLeftSemiJoinHash.scala: Set(package, BuildRight, asInstanceOf, isInstanceOf, <init>, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala: Set(package, BuildRight, BuildSide, BuildLeft, <init>, ==, !=, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/compressionSchemes.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, decoder, IntDelta, count, prevValue, wait, $asInstanceOf, BooleanBitSet, overflow, MAX_DICT_SIZE, productArity, equals, gatherCompressibilityStats, dictionary, PassThrough, asInstanceOf, run, RunLengthEncoding, valueCount, synchronized, $isInstanceOf, lastRun, prev, visited, dictionarySize, canEqual, typeId, Encoder, productPrefix, LongDelta, notifyAll, readResolve, isInstanceOf, compressedSize, uncompressedSize, <init>, encoder, BITS_PER_LONG, supports, _uncompressedSize, ==, compressionRatio, clone, compress, lastValue, currentWord, next, Decoder, values, toString, !=, getClass, ne, currentValue, hasNext, DictionaryEncoding, eq, productIterator, _compressedSize, ##, finalize, productElement, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressionScheme.scala: Set(IntDelta, BooleanBitSet, PassThrough, RunLengthEncoding, typeId, Encoder, LongDelta, compressedSize, uncompressedSize, <init>, Decoder, DictionaryEncoding)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(gatherCompressibilityStats, PassThrough, typeId, Encoder, compressedSize, encoder, supports, ==, compressionRatio, compress)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, StringType, NullType, createStructType, wait, equals, LongType, IntegerType, TimestampType, notifyAll, DoubleType, <init>, createStructField, DateType, createMapType, toString, getClass, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, hashCode, ShortType.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala: Set(<init>, DataType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ShortType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StringType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala: Set(<init>, DataType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/LongType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UserDefinedType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BinaryType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/TimestampType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/NullType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/MapType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/FloatType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/IntegerType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(DataType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DecimalType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/BooleanType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DateType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DoubleType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ArrayType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSQLContext.scala: Set(StringType, LongType, IntegerType, TimestampType, DoubleType, <init>, DateType, BooleanType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/JavaSchemaRDD.scala: Set(<init>, toString)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/ByteType.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(StringType, NullType, createStructType, LongType, IntegerType, TimestampType, DoubleType, <init>, createStructField, DateType, createMapType, createArrayType, BinaryType, BooleanType, DataType, ByteType, FloatType, ShortType)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashedRelation.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashedRelation.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashedRelation.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashedRelation.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashedRelation.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, $asInstanceOf, equals, asInstanceOf, HashedRelation, synchronized, $isInstanceOf, apply$default$3, notifyAll, isInstanceOf, <init>, apply, GeneralHashedRelation, ==, clone, toString, !=, get, getClass, getValue, UniqueKeyHashedRelation, ne, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastHashJoin.scala: Set(asInstanceOf, HashedRelation, isInstanceOf, <init>, apply, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashJoin.scala: Set(HashedRelation, <init>, apply, ==, !=, get, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/ShuffledHashJoin.scala: Set(asInstanceOf, HashedRelation, isInstanceOf, <init>, apply, ==, toString, eq)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/BroadcastNestedLoopJoin.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, children, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, copy$default$5, printSchema, map, productArity, equals, BroadcastNestedLoopJoin, treeString, transformChildrenDown, buildSide, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, left, codegenEnabled, nodeName, $isInstanceOf, streamed, boundCondition, x$1, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, references, <init>, mapChildren, condition, schema, transformExpressionsDown, apply, broadcast, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, sparkContext, outputPartitioning, copy$default$3, copy, inputSet, toString, logError, !=, collect, joinType, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, right, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(map, BroadcastNestedLoopJoin, buildSide, asInstanceOf, left, codegenEnabled, expressions, isInstanceOf, <init>, condition, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, joinType, output, ne, right)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/CS143Utils.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/CS143Utils.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/CS143Utils.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/CS143Utils.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/CS143Utils.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, getUdfFromExpressions, $asInstanceOf, equals, asInstanceOf, synchronized, getNewProjection, $isInstanceOf, notifyAll, isInstanceOf, getListFromBytes, apply, ==, getBytesFromList, generateCachingIterator, CS143Utils, clone, toString, CachingIteratorGenerator, !=, getClass, ne, getNextChunkBytes$default$3, getNextChunkBytes, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/basicOperators.scala: Set(asInstanceOf, getNewProjection, isInstanceOf, apply, ==, generateCachingIterator, CS143Utils, toString, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/DiskHashedRelation.scala: Set(getBytesFromList, CS143Utils)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetFilters.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetFilters.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetFilters.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetFilters.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetFilters.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, serializeFilterExpressions, wait, $asInstanceOf, PARQUET_FILTER_DATA, equals, asInstanceOf, synchronized, $isInstanceOf, notifyAll, isInstanceOf, deserializeFilterExpressions, ==, clone, createRecordFilter, toString, createFilter, !=, getClass, ParquetFilters, ne, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(asInstanceOf, isInstanceOf, ==, toString, createFilter, ParquetFilters, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala: Set(asInstanceOf, isInstanceOf, ==, createRecordFilter, toString, !=, getClass, ParquetFilters, ne, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(asInstanceOf, isInstanceOf, ==, toString, createFilter, !=, ParquetFilters, ne, eq)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDTWrappers.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, unapply, isPrimitive, wait, $asInstanceOf, UDTWrappers, equals, scalaUDT, json, wrapAsJava, asInstanceOf, synchronized, $isInstanceOf, JavaToScalaUDTWrapper, deserialize, typeName, ScalaToJavaUDTWrapper, notifyAll, isInstanceOf, <init>, prettyJson, userClass, ==, clone, pyUDT, toString, !=, sqlType, getClass, ne, serialize, wrapAsScala, jsonValue, javaUDT, eq, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(unapply, UDTWrappers, wrapAsJava, asInstanceOf, isInstanceOf, <init>, ==, ne, wrapAsScala)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, nullable, getDataType, name, wait, isNullable, getMetadata, equals, notifyAll, getName, <init>, metadata, toString, getClass, dataType, StructField, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructType.java[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/StructField.java[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/types/util/DataTypeConversions.scala: Set(nullable, getDataType, name, isNullable, getMetadata, getName, <init>, metadata, dataType, StructField)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/DataType.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, super$extractTo, wait, $asInstanceOf, nullsBuffer, equals, asInstanceOf, pos, synchronized, $isInstanceOf, nextNullIndex, notifyAll, initialize, isInstanceOf, super$hasNext, ==, clone, seenNulls, $init$, NullableColumnAccessor, toString, !=, getClass, extractTo, nullCount, ne, hasNext, eq, super$initialize, underlyingBuffer, ##, finalize, hashCode.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnAccessor.scala: Set(super$hasNext, hasNext, super$initialize)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnAccessor.scala: Set(super$extractTo, nullsBuffer, pos, nextNullIndex, super$hasNext, ==, seenNulls, NullableColumnAccessor, nullCount, super$initialize, underlyingBuffer)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(asInstanceOf, isInstanceOf, ==, toString, extractTo, nullCount, ne, hasNext, eq)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala: Set(asInstanceOf, initialize, ==, NullableColumnAccessor)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnAccessor.scala: Set(asInstanceOf, initialize, ==, NullableColumnAccessor)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/Generate.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, simpleString, outer, children, generator, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, numberedTreeString, printSchema, join, map, productArity, equals, treeString, transformChildrenDown, schemaString, argString, asInstanceOf, transformExpressions, generateTreeString, log_, synchronized, codegenEnabled, nodeName, $isInstanceOf, logTrace, asCode, canEqual, expressions, copy$default$4, outputSet, isTraceEnabled, makeCopy, transformUp, productPrefix, logName, notifyAll, otherCopyArgs, missingInput, isInstanceOf, stringArgs, child, references, <init>, mapChildren, schema, boundGenerator, Generate, transformExpressionsDown, apply, flatMap, executeCollect, ==, fastEquals, sqlContext, transformExpressionsUp, clone, newMutableProjection, newPredicate, foreach, sparkContext, outputPartitioning, copy$default$3, copy, inputSet, toString, logError, !=, collect, getClass, logWarning, output, copy$default$1, initializeIfNecessary, transformDown, transformAllExpressions, ne, generatorOutput, transform, withNewChildren, newProjection, statePrefix, eq, productIterator, log, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(outer, generator, join, map, asInstanceOf, codegenEnabled, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, ne)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	listStatus, notify, FilteringParquetRowInputFormat, simpleString, children, newJobContext, isSplitable, execute, wait, requiredChildDistribution, copy$default$2, $asInstanceOf, validateProjection, partOutput, numberedTreeString, relation, listFiles, printSchema, map, productArity, pruneColumns, equals, treeString, transformChildrenDown, schemaString, argString, saveAsHadoopFile, asInstanceOf, transformExpressions, normalOutput, generateTreeString, log_, getFooters, synchronized, codegenEnabled, nodeName, $isInstanceOf, FileSystemHelper, findMaxTaskId, getReadSupport, newTaskAttemptContext, getFormatMinSplitSize, InsertIntoParquetTable, getSplits, logTrace, asCode, canEqual, expressions, outputSet, isTraceEnabled, getTaskSideSplits, makeCopy, transformUp, getTaskAttemptID, getBlockIndex, productPrefix, logName, notifyAll, attributes, getRecordWriter, computeSplitSize, otherCopyArgs, missingInput, isInstanceOf, stringArgs, columnPruningPred, child, firstAvailableClass, references, <init>, AppendingParquetOutputFormat, getOutputCommitter, newTaskAttemptID, mapChildren, schema, transformExpressionsDown, apply, blockLocationCache, flatMap, executeCollect, ==, checkOutputSpecs, createRecordReader, fastEquals, sqlContext, getDefaultWorkFile, transformExpressionsUp, clone, newMutableProjection, newPredicate, getWriteSupport, foreach, sparkContext, ParquetTableScan, fileStatuses, outputPartitioning, copy$default$3, copy, inputSet, toString, logError, !=, footerCache, collect, getClass, logWarning, output, copy$default$1, initializeIfNecessary, overwrite, transformDown, transformAllExpressions, ne, transform, withNewChildren, getGlobalMetaData, newProjection, statePrefix, footers, eq, productIterator, log, ##, newOrdering, finalize, productElement, transformChildrenUp, hashCode, getClientSideSplits, getNodeNumbered, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala: Set(relation, map, asInstanceOf, codegenEnabled, expressions, isInstanceOf, child, <init>, apply, flatMap, ==, sqlContext, sparkContext, toString, collect, output, overwrite, ne)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/newParquet.scala: Set(listStatus, FilteringParquetRowInputFormat, newJobContext, map, asInstanceOf, getSplits, expressions, isInstanceOf, references, <init>, schema, apply, flatMap, ==, sqlContext, foreach, sparkContext, toString, !=, output, ne, transform, eq, logInfo)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/package-info.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/package-info.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/package-info.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/package-info.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/package-info.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala)[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala[0m
[0m[[0mdebug[0m] [0mIncluding /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala by /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala, /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	notify, wait, $asInstanceOf, equals, gatherCompressibilityStats, asInstanceOf, columnStats, log_, synchronized, isWorthCompressing, $isInstanceOf, build, logTrace, isTraceEnabled, super$appendFrom, initialize$default$3, logName, notifyAll, initialize, isInstanceOf, ==, clone, compressionEncoders, $init$, appendFrom, toString, initialize$default$2, logError, !=, getClass, logWarning, initializeIfNecessary, CompressibleColumnBuilder, ne, eq, log, super$initialize, ##, finalize, hashCode, logDebug, logInfo, initializeLogging.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(gatherCompressibilityStats, isWorthCompressing, super$appendFrom, ==, compressionEncoders, CompressibleColumnBuilder, super$initialize, logDebug)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/NullableColumnBuilder.scala: Set(columnStats, super$appendFrom, super$initialize)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/InMemoryColumnarTableScan.scala: Set(asInstanceOf, columnStats, build, isInstanceOf, ==, appendFrom, toString, ne, eq, logInfo)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/compression/CompressibleColumnBuilder.scala: Set(gatherCompressibilityStats, isWorthCompressing, super$appendFrom, ==, compressionEncoders, CompressibleColumnBuilder, super$initialize, logDebug)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(asInstanceOf, columnStats, initialize, ==, CompressibleColumnBuilder)[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/columnar/ColumnBuilder.scala: Set(asInstanceOf, columnStats, initialize, ==, CompressibleColumnBuilder)[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF12.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF12.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF12.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF12.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF12.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF12.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF12)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF12.java[0m
[0m[[0mdebug[0m] [0mInvalidating /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF21.java...[0m
[0m[[0mdebug[0m] [0mInvalidating (transitively) by inheritance from /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF21.java...[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF21.java)[0m
[0m[[0mdebug[0m] [0mInvalidated by transitive inheritance dependency: Set(/Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF21.java)[0m
[0m[[0mdebug[0m] [0mThe /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF21.java source file has the following regular definitions changed:[0m
[0m[[0mdebug[0m] [0m	call, UDF21.[0m
[0m[[0mdebug[0m] [0mAll member reference dependencies will be considered within this context.[0m
[0m[[0mdebug[0m] [0mThe following modified names cause invalidation of /Users/bleonard/Documents/Databases/spark/sql/core/src/main/scala/org/apache/spark/sql/api/java/UDFRegistration.scala: Set(call, UDF21)[0m
[0m[[0mdebug[0m] [0mName hashing optimization doesn't apply to non-Scala dependency: /Users/bleonard/Documents/Databases/spark/sql/core/src/main/java/org/apache/spark/sql/api/java/UDF21.java[0m
[0m[[0mdebug[0m] [0mNew invalidations:[0m
[0m[[0mdebug[0m] [0m	Set()[0m
[0m[[0mdebug[0m] [0mInitial set of included nodes: Set()[0m
[0m[[0mdebug[0m] [0mPreviously invalidated, but (transitively) depend on new invalidations:[0m
[0m[[0mdebug[0m] [0m	Set()[0m
[0m[[0mdebug[0m] [0mAll newly invalidated sources after taking into account (previously) recompiled sources:Set()[0m
